
\begin{landscape}\begingroup\fontsize{9}{11}\selectfont
\rowcolors{2}{white}{gray!6}

\begin{longtable}[t]{>{\bfseries\raggedright\arraybackslash}p{10em}>{\raggedright\arraybackslash}p{30em}>{\raggedright\arraybackslash}p{15em}>{\raggedright\arraybackslash}p{3em}>{\raggedright\arraybackslash}p{15em}}
\caption{\label{tab:}Modules for \textbf{'Improving the Reproducibility of Experimental Data Pre-Processing'}. The color of each module's title indicates whether the module focuses on \textbf{Principals} (blue), \textbf{Implementation} (red), or \textbf{Case study examples} (black).}\\
\hiderowcolors
\toprule
Module title & Description of module content & Objectives (After taking the module, the trainee can ...) & Video Length & Extra educational materials\\
\midrule
\endfirsthead
\caption[]{Modules for \textbf{'Improving the Reproducibility of Experimental Data Pre-Processing'}. The color of each module's title indicates whether the module focuses on \textbf{Principals} (blue), \textbf{Implementation} (red), or \textbf{Case study examples} (black). \textit{(continued)}}\\
\toprule
Module title & Description of module content & Objectives (After taking the module, the trainee can ...) & Video Length & Extra educational materials\\
\midrule
\endhead
\
\endfoot
\bottomrule
\endlastfoot
\showrowcolors
\textcolor{blue}{\textbf{Principals and benefits of scripted pre-processing of experimental data}} & The experimental data collected for biomedical research often requires 
      pre-processing before it can be analyzed (e.g., gating of flow cytometry data, 
      peak finding and quantification for LC / MS metabolomics data). While 
      often proprietary, point-and-click software is available for this pre-processing,
      use of such software can limit the transparency and reproducibility of this 
      pre-processing stage of the analysis, and point-and-click software is often 
      time-consuming to use for repeated tasks over large research projects.
      In this module, we will explain how using scripts to apply open source software 
      for this pre-processing step can improve the transparency, reproducibility, and
      transparency of research. & \tabitem Define pre-processing of experimental data and give some examples; 

      \tabitem Describe how the use of proprietary software for pre-processing experimental
      data limits transparency and reproducibility; 

      \tabitem Understand what an open source
      code script is and how it can be used as an alternative in pre-processing 
      experimental data; 

      \tabitem List some popular packages in R that can be used to 
      pre-process biomedical experimental data. & 15 & \tabitem Discussion questions, including discussion of which steps are commonly used to 
      pre-process experimental data in the trainee's research area; 
      
      \tabitem Short audio recording of two Co-Is giving their
      own answers to these discussion questions; 
      
      \tabitem List of some popular R packages for
      pre-processing different types of biomedical experimental data.\\
\textcolor{red}{\textbf{Introduction to R code scripts}} & In this module, we will explain the difference between interactive software use and the
      use of code scripts, using examples from R. We will then demonstrate how to 
      create, save, and run an R code script for a simple data cleaning task. & \tabitem Describe what an R code script is and how it differs from interactive
      coding in R; 

      \tabitem Create and save an R script to perform a simple data 
      pre-processing task; 
  
      \tabitem Run an R script. & 10 & \tabitem Applied exercise: Given a simple example dataset and a data cleaning task, 
      write and run an R script to perform the task. Then adapt that script to re-use
      it on a second, similar example dataset. Hints on useful R functions will be 
      provided to help trainees new to the R language; 

      \tabitem Video providing a detailed
      walk-through of a solution to the applied exercise.\\
\textcolor{red}{\textbf{Simplify scripted pre-processing through R's 'tidyverse' tools}} & The R programming language now includes a collection of 'tidyverse' extension 
      packages that enable user-friendly yet powerful work with experimental data,
      including pre-processing and exploratory visualizations. The principal behind
      the 'tidyverse' is that a collection of simple, general tools can be joined 
      together to solve complex problems, as long as a consistent format is used 
      for the input and output of each tool (the 'tidy' data format taught in other
      modules). In this module, we will explain why this 'tidyverse' system is so
      powerful and how it can be leveraged within biomedical research, especially for
      reproducibly pre-processing experimental data. & \tabitem Define R's 'tidyverse' system; 

      \tabitem Explain how the 'tidyverse' collection
      of packages can be both user-friendly and powerful in solving many complex
      challenges in working with data; 

      \tabitem Describe the difference between 'base R' and
      R's 'tidyverse'. & 15 & \tabitem Quiz: Questions will test the trainee's understanding of what R's 
      'tidyverse' is and why it is a powerful yet user-friendly tool for improving
      the reproducibility, transparency, and efficiency of research projects. 

      \tabitem Video with detailed answers and explanations for the quiz questions; 

      \tabitem Links to further free sources for developing more 'tidyverse' coding 
        skills.\\
\textcolor{blue}{\textbf{Complex data types in experimental data pre-processing}} & Raw data from many biomedical experiments, especially those that
  use high-throughput techniques, can be very large and complex. Because of the 
  scale and complexity of these data, software for pre-processing the data in R
  often uses complex, 'untidy' data formats. These complex data formats are necessary
  for computational efficiency and to aid the structure of the pre-processing
  software, but the 'untidy' formats add a critical barrier for researchers who 
  wish to explore and visualize the data. In this module, we will 
  describe the complex data formats are often used in open source software for 
  pre-processing experimental data, explain why use of these complex formats is
  often necessary, and outline how these complex formats create hurdles in 
  implementing reproducibility tools among laboratory-based scientists. & \tabitem Explain why R software for pre-processing biomedical data often stores the 
  data in complex, 'untidy' formats; 
  
  \tabitem Describe how these complex data formats can create barriers to 
  laboratory-based researchers seeking to use reproducibility tools for 
  data pre-processing. & 15 & \tabitem Quiz: Determine trainee's understanding of why complex data formats
  are often used within steps of experimental data pre-processing in open-source
  software; 
  
  \tabitem Video providing detailed
  answers to quiz questions.\\
\textcolor{red}{\textbf{Complex data types in R and Bioconductor}} & Many R extension packages for pre-processing experimental data use complex (rather than
    'tidy') data formats within their code, and many output data in complex formats. This
    is necessary for computational efficiency of the pre-processing, but creates a hurdle
    for using many common tools taught to improve research reproduciblity, 
    including R's 'tidyverse' tools. With the rising popularity of the 'tidyverse' collection of R tools, which require
      data to be in a 'tidy' format, R users have recognized that the use of complex, 'untidy'
  data formats can complicate reproducible code for data pre-processing, analysis,
  and visualization. Very recently, some researchers have developed tools 
  (the broom and biobroom R package extensions) that
  can extract a 'tidy' dataset from data stored in a complex, list-based format.
  These tools create a clean, simple connection between the complex data formats
  often used in pre-processing or modeling experimental data and the 'tidy' format
  required to use the 'tidyverse' tools now taught in many introductory R courses. In this module, we will describe the 'list' data structure,
    the common backbone for complex data structures in R, and well as provide tips on how to
  explore and extract data stored in R in this format. 
      We will then demonstrate how the new \textit{broom} and \textit{biobroom} packages 
    can be used to extract  to use  to convert output from pre-processing software to 'tidy'
    data formats for futher steps of reproducible data visualization and analysis. 
      'tidy' versions of pre-processed experimental data from their complex data formats,
      to allow user-friendly data analysis and visualization using the widely-taught
      general 'tidyverse' tools. & \tabitem Describe the structure of R's 'list' data
      format; 

      \tabitem Take basic steps to explore
      and extract data stored in R's complex, list-based structures;
  
      \tabitem Describe what the \textit{broom} and \textit{biobroom} R packages can do; 

      \tabitem Explain why 
  converting data from a complex format to a 'tidy' format can improve the 
  transparency and reproducibility of a research project. & 15 & \tabitem Applied exercise: We will provide example data in a complex, list-based format. 
  The trainee will explore this data based on step-by-step instructions and will 
  extract specified elements from the data format as well as practice using \textit{broom} and
  \textit{biobroom} R packages to extract 'tidy' data from complex data formats.; 
  
  \tabitem Video providing a detailed
  walk-through of completing this exercise, with explanations for specific steps.\\
\addlinespace
\textcolor{black}{\textbf{Example: Converting from complex data types to 'tidy' data formats}} & We will provide a detailed example of a case where data pre-processing in R
      has resulted in data in a complex, 'untidy' format, and where tools can be 
      used to extract data in a 'tidy' format, which then can easily integrate
      with general R 'tidyverse' tools for data analysis and visualization. We will
      walk through an example of applying automated gating to flow cytometry data. 
      We will demonstrate the complex initial format of this pre-processed data and then
      show trainees how a 'tidy' dataset can be extracted and used for further data
      analysis and visualization. This example will use real experimental data from 
      research on the immunology of tuberculosis [more details on this project]. & \tabitem List R package extenstions that can be used to extract 'tidy' data from 
      complex, 'untidy' R data formats; 

      \tabitem Describe how these tools can be used in 
      research projects to shift from data pre-processing to analysis and visualization
      of the processed data. & 20 & \tabitem Applied exercise: Trainees will be given an example dataset in a complex, 
      'untidy' data format in R and will be instructed in how to convert it to 
      a 'tidy' format and then create some straightforward plots of the data based on 
      this 'tidy' dataset; 

      \tabitem Video demonstrating a detailed solution to the applied
      exercise.\\
\textcolor{blue}{\textbf{Introduction to reproducible data pre-processing protocols}} & Reproducibility tools can be used to create reproducible data pre-precessing 
    protocols---documents that combine code and text in a 
  'knitted' document ... . In this module, we will describe how
  reproducible data pre-processing protocols 
  can be leveraged early in a research project to improve the reproducibility 
  of the pre-processing of experimental data and to ensure transparency, consistency,
  and reproducibility across the research projects conducted by a research team. & \tabitem Describe a reproducible data pre-processing protocol; 
  
  \tabitem Explain how reproducible data pre-processing protocol can be used to improve
    the reproducibility
  of research projects at the data pre-processing phase; 
  
  \tabitem List other benefits of using reproducible data pre-processing protocols,
    including improving efficiency and consistency of data pre-processing across a
    research groups research projects. & 15 & \tabitem Discussion questions: Including discussion of how reproducible data pre-processing 
  protocols can make biomedical research more reproducible at the data pre-processing stage; 
  
  \tabitem Short audio 
  recording of two Co-Is giving their
  own answers to these discussion questions.\\
\textcolor{red}{\textbf{Introduction to RMarkdown as a tool for creating reproducible data pre-processing protocols}} & RMarkdown can be used to create documents that combine code and text in a 
      'knitted' document, and it has become a popular tool among statisticians
      and data scientists for improving the computational reproducibility and 
      efficiency of their research. This tool can also be used earlier in the 
      research process, however, to develop well-documented code to pre-process
      raw experimental data. In this module, we will show trainees the types of 
      documents that can be created and run using RMarkdown. We will describe how
      RMarkdown is used among statisticians to improve the reproducibility, 
      efficiency, and transparency of data analysis, as well as describe how it 
      can be leveraged earlier in a research project to improve the reproducibility 
      of the pre-processing of experimental data. We will also provide detailed instructions on how to use RMarkdown
      in RStudio to create documents that combine code and text. We will explain how
  these documents can be converted into different final file formats (PDF, HTML,
  Microsoft Word). We will show how an RMarkdown document describing a data 
  pre-processing protocol can be used to efficiently apply the same data
  pre-processing steps to different sets of raw data. & \tabitem Define RMarkdown; 

      \tabitem Describe the documents that can be created using
      RMarkdown; 

      \tabitem Explain how RMarkdown can be used to improve the reproducibility
      of research projects at the data pre-processing phase; 
  
      \tabitem Create a document in RStudio using 
      RMarkdown; 
  
  \tabitem Render the document in 
  multiple file formats; 
  
  \tabitem Apply the document to several different datasets
  that follow the same format. & 15 & \	abitem Applied exercise: Trainees will be asked to create, save, and render 
    their own RMarkdown document through RStudio; 
  
  \tabitem Video providing a detailed
  walk-through of a solution to the applied exercise.\\
\textcolor{black}{\textbf{Example: Creating a reproducible data pre-processing protocol}} & We will provide an example of creatin a reproducible protocol for the automated
      gating of flow cytometry data for a project on the immunology of tuberculosis
      [more details on project]. This data pre-processing protocol was created 
      using RMarkdown and allows the efficient, transparent, and reproducible 
      gating of flow cytometry data for all experiments in a research project. We will
      walk the trainees through the final pre-processing protocol, how we apply this
      protocol to new experimental data, and how we developed the protocol initially. & \tabitem Explain how a reproducible data pre-processing protocol can be integrated
      into a real research project; 

      \tabitem Describe what is included in a data 
      pre-processing protocol; 

      \tabitem Understand how to design and implement a data
      pre-processing protocol to replace manual or point-and-click data pre-processing
      tools. & 20 & \tabitem Quiz questions: These will test the trainees understanding of how and why we 
      created well-documented and reproducible data pre-processing protocols for this 
      project, as well as how this helps increase the transparency and reproducibility
      of the research project; 

      \tabitem Short audio recording of discussion with the head of
      this example research project on how this reproducible data pre-processing fits into
      her research project and how use of this protocol differs from previous data
      pre-processing practices in the group.\\*
\end{longtable}
\rowcolors{2}{white}{white}\endgroup{}
\end{landscape}

\documentclass[pdftex,english,11pt,parskip=half]{scrartcl}
\usepackage{palatino}
\usepackage{mathpazo}
\usepackage[margin=0.6in]{geometry}
%\usepackage{parskip}
\usepackage[compact]{titlesec}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{babel}
\usepackage{framed}
\usepackage{wrapfig}
\usepackage{subfig}
\usepackage{sidecap}
\usepackage[labelfont=bf,font=small,format=plain]{caption}
\usepackage{doi}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage{array}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{float}
%\usepackage[authoryear]{natbib}
\usepackage[numbers]{natbib}
\usepackage{url,hyperref,color}
\usepackage{rotating}
\usepackage{lscape}
\definecolor{darkblue}{rgb}{0.0,0.0,0.75}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}
\newcommand{\fixme}[1]{{\color{red} #1}}
\renewcommand\thesection{\Alph{section}}
\renewcommand{\familydefault}{\sfdefault}
\newcommand{\tabitem}{~~\llap{\textbullet}~~}
\begin{document}
\addtokomafont{section}{\large}
\def\bf{\normalfont\bfseries}
\pagestyle{empty}

\section*{Research Education Program Plan}

\section{Significance}
\vspace{-0.1in}

Current focal points of NIH-funded biomedical research include translational
medicine, big data analyses of genomic, proteomic, and metabolomic experiments,
and team science \cite{}, all of which rely on the generation, sharing, and
integration of high-quality experimental data that may be used and re-used in
multiple types of analysis and visualization platforms. The NIH Strategic Plan
for Data Science \cite{} emphasizes the critical need to capitalize on this
emerging ecosystem of data, and includes the need to address multiple practical
issues related to data storage, management, accessibility, and usablility.
However, consideration of the current sources of much of this data from
individual bench scientists and academic research groups, leads to the 
recognition that a large amount of biomedical data collection is in the form 
of commercial or open source spreadsheets that contain sometimes complex 
organizational
patterns of quantitative and qualitative tables, charts, graphs, notes and other
figures, embedded black-box statistical calculations, and mixtures of
experimental data types and units. Further, it is widely known and discussed
among data scientists, mathematical modelers, and statisticians \cite{}, that
there is a frequent need disgard, transform, and reformat sometimes large
amounts of this primary data and meta-data. While such ``data cleaning'' is
necessary for it's use in the advanced and developing data tools, it is often
conducted by the data-scientist with minimal or no communcation with those who
generated the data. From our experience with drug and vaccine development for
infectious diseases, \textbf{we have identified this step of data recording and
pre-processing as a potential critical point of failure for reproducible
research results.} In this proposal, we provide a solution to mitigate such
potential failures by using the R programming language and the concept of "tidy"
data stuructures, together with a set of training modules that are aimed at the
laboratory bench scientists whose attention is rather to their experimental
technique and collection of accurate data, and who may have little or no
background in the use of general purpose software tools.

While this proposal uses examples from microbiology and immunology experiments,
the collection of primary data in a flexible, open source, transpararent, 
and reproducible format, which can be kept in it's primary state without the 
need for additional modification, is a solution that extends thoughout
large and small scale biomedical science projects.  Figure () below shows an 
example workflow of such a comprehensive experimental data and quantitative 
analysis framework, and indicates our specific focus, highlighting it's 
critical place in such an analysis framework.

\section{Innovation} \vspace{-0.1in}

\textbf{We will use the
innovative \textit{bookdown} framework \cite{xie2016bookdown} to structure and
publish all of our training materials as a free and open online book, with embedded video lectures and additional educational materials}. The
\textit{bookdown} framework has been available for a little over two years and
extends the principles of \textit{Rmarkdown} \cite{xie2015dynamic} to allow authors to create attractive
online books that integrate programming code and text. With this format, code examples and related
output do not need to be copied and pasted into a document, but instead is
automatically generated. Through this innovative framework, we
will create a searchable online book that weaves R code into the text
and includes embedded video lectures, active web links to online
references, and computationally reproducible examples and exercises
(Figure \ref{fig:prototype}). Further, trainees will be able to
download the book as either a PDF or EPUB file, to use as a reference as they
continue learning to implement reproducibility tools in their research projects. Even though this framework is new, it has proven
itself reliable and effective---it serves as the framework for several extremely
popular and highly-accessed books on R programming, including the extremely popular book \textit{R for Data
Science} \cite{wickham2016r}. 

\begin{figure}[t] \includegraphics[width =
\textwidth]{figures/book_prototype.jpg} \caption{Prototype of online course
book, with features highlighted.} \label{fig:prototype} \end{figure}

Dr. Anderson (PI) is an early adopter of the \textit{bookdown} framework and served as an expert reviewer for \textit{bookdown: Authoring Books
and Technical Documents with R Markdown} \cite{xie2016bookdown}. Since
the \textit{bookdown} framework became available, she has used it to create two openly-available online
books: the \textit{R Programming for Research} online coursebook (https://geanders.github.io/RProgrammingForResearch/), which she uses
as a joint textbook and website for the \textit{R Programming for Research}
course she teaches each fall at Colorado State University, and \textit{Mastering
Software Development in R} (https://bookdown.org/rdpeng/RProgDA/), which she co-wrote with Dr. Roger Peng as a manual
for developing advanced R programming skills and which has been downloaded by
over 14,000 people from LeanPub (see letter from Dr. Peng). 

\textbf{The use of this framework will help us effectively reach a large
audience of laboratory-based biomedical researchers in need of training materials to improve the reproducibility of data
recording and pre-processing.} We will 
post this book online using the \textit{GitHub Pages} \cite{gitpages}, as we have done
with a previous book created with the same framework \cite{andersoncoursebook}. This will allow anyone to
freely access this content online. We will publish both the current version of the developing book and its underlying code openly online from the beginning
of our development of the training materials. \textbf{By making the training
materials available from day one, as they are developed, we will be able to
attract early users to help disseminate the material as it evolves and also be
able to get early feedback.} Once the online
book is developed, we will submit a static version of it to be posted
on the homepage of the \textit{bookdown.org} website \cite{bookdownorg}, providing
another way for our key audience of laboratory-based biomedical researchers to find and access the materials.

\section{Approach---Proposed Research Education Program}

\subsubsection*{Project goals and objectives.} 

Our team combines experts in R programming
(Anderson, Lyons) with a group of biomedical researchers (Gonzalez-Juarrero,
Henao-Tamayo, and Robertson) who have, collectively, spent decades in
laboratory-based research to improve understanding of tuberculosis and other
diseases. We met as faculty members of the same College at Colorado State
University, and since have discovered how many of the tools that Drs. Anderson
and Lyons teach and use to improve the reproducibility of \textit{data analysis}
for biomedical research can substantially improve reproducibility and
transparency in the laboratory-based biomedical research projects of Drs.
Gonzalez-Juarrero, Henao-Tamayo, and Robertson at the stages of \textit{data
recording} and \textit{data pre-processing}. Improving the computational 
research at these stages is critical, as these steps form the foundation and 
provide the input for the later stages of data analysis, visualization and 
interpretation---if data recording and pre-processing are not reproducible, there 
is no chance to make the full research project computationally reproducible.
Further, improving the computational reproducibility of the steps of data recording and pre-processing makes collaborations with
statisticians 
and data analysts more efficient and less prone to errors \cite{ellis2018share}, 
encouraging productive and high-quality ``Team Science" \cite{munafo2017manifesto}.

Over the past year, we have begun
to work together to do this within our own research projects: for example, in
Fall 2017 Dr. Gonzalez-Juarrero attended Dr. Anderson's (PI) course in \textit{R
Programming for Research} and has brought the ideas and techniques back to her
research laboratory, in Fall 2017 Dr. Lyons worked with Dr. Anderson to bring in
real tuberculosis drug development data to use in the final group project in Dr.
Anderson's R Programming course, and in Spring 2018 Dr. Henao-Tamayo and Dr.
Anderson began co-advising a graduate student with the aims of implementing
open-source tools for pre-processing flow cytometry in Dr. Henao-Tamayo's
laboratory. Collectively, we are passionate about the idea that
\textbf{open-source tools can be used to bring substantial improvements to
reproducibility of data recording and pre-processing in laboratory-based
research}, and yet we are also able to recognize the key barriers in
implementing these tools in this setting, as well as in training
laboratory-based researchers in how to use these tools, and why existing free
training materials have, to date, been limited in meeting these needs for the
key audience of laboratory-based biomedical researchers. 

We aim to create training modules that will show laboratory-based biomedical
researchers how simple computational reproducibility principles can improve
biomedical research reproducibility at the stages of data recording and
preprocessing, as well as teach them how to implement these principles in their
laboratories. The importance of such computational reproducibility of scientific
research is increasingly recognized by scientists, journals, and funding
agencies, with such ``computationally reproducible" research requiring that all
data and code for a research project be available and that this data and code
can be used to regenerate study findings either by the original researcher or by
other researchers \cite{ellis2018share, ram2013git}. Among our team, we have
found that there are many common existing practices---including use of
spreadsheets with embedded macros to concurrently record and analyze
experimental data, problematic management of project files,
reliance on proprietary, vendor-supplied point-and-click software for data
pre-processing---that can interfere with the transparency, reproducibility, and
efficiency of the kind of research they conduct. These problems have also been 
identified by others as key barriers to research reproducibility 
\cite{broman2018data, bryan2018excuse, ellis2018share, marwick2018packaging}.
Our team has worked together to craft a list of
specific topics (Tables \ref{tab:content_one} and \ref{tab:content_two}) we aim
to address, choosing topics that tackle barriers to Reproducibility with
straightforward fixes, but which we have found are still very common in
biomedical laboratory-based research programs, including those here at Colorado
State University. 

The reproducibility of data recording and pre-processing is typically 
in the hands of laboratory-based, rather than computationally-based, researchers.
Many excellent free training resources exist to improve the computational
reproducibility of biomedical research. However, most of these
materials---including some developed by Dr. Anderson for her open online and
CSU-based courses in R programming [refs]---target researchers at the stage of
\textit{data analysis}, and provide much less guidance on the principles and
techniques to improve reproducibility of the earlier steps of
\textbf{experimental data recording} and \textbf{experimental data
pre-processing}. Training materials that are short, 
modular, and accessible can help fill a critical need in providing laboratory-based biomedical researchers this needed
training \cite{munafo2017manifesto} and have proven very popular in providing 
similar training to the audience of data scientists and statisticians \cite{leek2015opinion}. 

Our project's \textbf{primary goal} is to develop
training modules that address the needs of laboratory-based biomedical
researchers seeking to improve reproducibility, especially of experimental data
recording and pre-processing, in their research projects. The \textbf{expected result} of
this project is an online book that contains twenty short training modules as separate
chapters, with video lectures, written text, and additional educational
materials collected within each module's chapter. We consider it critical that
these training materials be clear, relevant, and useful to a key audience of
biomedical scientists whose primary research activities focus on laboratory
research, rather than data analysis or statistics. 

\subsubsection*{Proposed training modules}

We propose to develop two collections of modules, \textbf{Improving the
Reproducibility of Experimental Data Recording} and \textbf{Improving the
Reproducibility of Experimental Data Pre-Processing}. Our team has worked
together to create a curriculum of training modules that we believe will help
fill an important training gap for laboratory-based biomedical researchers
(Tables \ref{tab:content_one} and \ref{tab:content_two}). The first sequence,
\textbf{``Improving the Reproducibility of Experimental Data Recording"} (Table
\ref{tab:content_one}), will explore the pitfalls of combining experimental data
recording and analysis within macro-enabled spreadsheets, explain the power of
structured data formats for recording data, describe how reproducibility can be
improved by using a single structured directory to store all research project
files, and demonstrate the use of version control to maintain single, current
versions of all files while saving a history of all file changes. The second
sequence, \textbf{``Improving the Reproducibility of Experimental Data
Pre-Processing"} (Table \ref{tab:content_two}), will focus on improving the
reproducibility of experimental data pre-processing steps, like gating for flow
cytometry data and peak finding / quantification for mass spectrometry data.
Training materials will explain how the use of code scripts for these steps
dramatically improves reproducibility compared to using vendor-supplied
point-and-click software and will introduce trainees to popular R software for
this pre-processing. This sequence will include advice on reproducible data
pre-processing protocols and how to create them using literate programming tools
(\textit{Rmarkdown}).

Each module will fall into one of three categories for teaching reproducibility:
(1) Principals; (2) Implementation; and (3) Examples. ``Principals"
modules will be programming-language agnostic, while ``Implementation" modules
will focus on tools available through the popular open source R software and its
RStudio interface. The ``Examples" modules can be used as a template for implementing R-based tools, but can also provide a top-level overview for non-programmers of how these tools can improve real biomedical research projects. Working with the biomedical laboratory-based co-investigators
on our team, we will ensure that these modules and the examples used in them are
approachable and useful to researchers with limited computational training. We
have divided the content into modules in a way that will allow \textbf{trainees
and investigators at any level} to create their own ``tracks" by selecting
relevant subsets of the modules to complete, and potentially combining this
content with other training modules available through the National Institute of General Medical Science's \textit{Clearinghouse for Training Modules to Enhance Data Reproducibility}
[ref]. Table \ref{tab:tracks} gives a few examples of how different trainees
could create and follow their own ``track" of through the training material we propose to develop.

\underline{\textbf{Improving the Reproducibility of Experimental Data
Recording}} 

The first sequence will provide principles and tools for improving
computational reproducibility at the stage of experimental data recording. This sequence will include eleven modules covering four main topics: 

\textbf{1. Separating data recording and analysis.} Many biomedical laboratories currently use spreadsheets---with formulas creating underlying connections between spreadsheet cells---to jointly record, visualize, and analyze experimental data \cite{broman2018data}. This practice impedes the transparency and reproducibility of both data recording and data analysis. When a research group develops and uses an evolving spreadsheet template that uses embedded formulas to analyze and visualize the data as soon as it is collected, it can leads to a data recording set-up for the laboratory that is extraordinarily opaque and complex (e.g., Figure \ref{fig:spreadsheet}). To improve the computational reproducibility of a research project, it is critical for biomedical researchers to learn the importance of maintaining the recorded experimental data as a ``read-only" file, and separating and pre-processing and analysis steps and rigorously keeping code and formula for these steps outside of the file used to record the data \cite{broman2018data, marwick2018packaging}. Further, statisticians have outlined specific methods that an experimental scientist can take to ensure that data shared in an Excel spreadsheet are shared in a reliable and reproducible way, including avoiding macros, using a separate Excel file for each dataset, recording descriptions of the variables in a separate code book rather than in the Excel file, avoiding the use of color of the cells to encode information, using ``NA" to code missing values, avoiding spaces in column headers, and avoiding splitting or merging cells \cite{ellis2018share, broman2018data}. This topic will covered in a \textit{Principles} module on ``Separating data
recording and analysis". Key readings for this section will be \cite{broman2018data} and \cite{ellis2018share}.

\begin{figure}[t] \centering \includegraphics[width =
0.8\textwidth]{figures/algorithms.png} \caption{An \textit{xkcd} cartoon
captures the ballooning complexity and lack of transparency that can result from
a group using an evolving spreadsheet with formulas connecting cells. This practice can be a
critical barrier to reproducibility and transparency in biomedical research, yet
is still a common practice in many biomedical laboratories \cite{broman2018data, marwick2018packaging}. \textit{Source: xkcd
by Randall Munroe}} \label{fig:spreadsheet} \end{figure}

\textbf{2. Using a structured data format to record data.} Every extra step of data
cleaning is another chance to introduce errors in the data, and yet laboratory-based researchers often share experimental data with collaborators in a format that requires extensive additional cleaning before it can be input into data analysis \cite{broman2018data}. Recording data in a ``structured" format brings many benefits for later stages of the research process, especially in terms of improving reproducibility and reducing the probability of errors in analysis \cite{ellis2018share}. Data that is in a structured tabular, two-dimensional format is substantially easier for collaborators like statisticians to understand and work with, without additional data formatting \cite{broman2018data}. Further, by using a consistent structured format across many or all data in a research project, it becomes much easier to create solid, well-tested code scripts for data pre-processing and analysis and to apply those scripts consistently and reproducibly across the datasets from multiple experiments \cite{broman2018data}. However, many biomedical researchers are unaware of this simple yet powerful strategy in data recording and how it can improve the efficiency and effectiveness of collaborations \cite{ellis2018share}. 

The ``tidy" data format is one implementation of a tabular, two-dimensional structured data format that has quickly gained popularity among statisticians and data scientists since it was defined in a 2014 paper \cite{wickham2014tidy}. The ``tidy" data
format plugs into R's \textit{tidyverse} framework, which enables powerful and
user-friendly data management, processing, and analysis by combining simple
tools to solve complex, multi-step problems
\cite{ross2017declutter, silge2016tidytext, wickham2016ggplot2, wickham2016r}. Since the \textit{tidyverse} tools are simple and share a
common interface, they are easier to learn, use, and combine than tools created
in the classical R framework \cite{ross2017declutter, lowndes2017our,
reviewer2017review, mcnamara2016state}. This \textit{tidyverse} framework is
quickly becoming the standard taught in introductory R courses and books
\cite{hicks2017guide, baumer2015data, kaplan2017teaching, stander2017enthusing,
reviewer2017review, mcnamara2016state}, ensuring ample training resources for
researchers new to programming, including books (e.g., \cite{baumer2017modern,
lifesciencesR}, some freely available online, e.g., \cite{wickham2016r}),
massive open online courses (MOOCs), on-site university courses
\cite{baumer2015data, kaplan2017teaching, stander2017enthusing}, and Software
Carpentry workshops \cite{wilson2014software, pawlik2017developing}. Further,
tools that extend the tidyverse have been created to enable high-quality data
analysis and visualization in several domains, including text mining
\cite{silge2017text}, microbiome studies \cite{mcmurdie2013phyloseq}, natural
language processing \cite{RJ-2017-035}, network analysis \cite{RJ-2017-023},
ecology \cite{hsieh2016inext}, and genomics \cite{yin2012ggbio}. 

This topic will
be covered in a \textit{Principles} module on ``Principles and power of
structured data formats", two \textit{Implementation} modules on ``The 'tidy'
data format: an implementation of a structured data format" and ``Designing
templates for tidy data collection", and one \textit{Example} module called
``Example: Creating a template for 'tidy' data collection". Key readings for this section will be \cite{broman2018data} and \cite{wickham2014tidy}. 

\textbf{3. Managing all research project files in a single, structured directory.}
Reproducbility can also be improved, starting at the data recording stage or
earlier, by using single, structured directory to store all files related to the
project. This ``project" framework of structured and thoughtful file management has recently been encouraged by a number of
researchers as a way to enable computationally reproducible research, especially
for research conducted by teams \cite{marwick2018packaging,
parker2017opinionated, lowndes2017our}. If a consistent structure is used for these directories across different research projects, it can substantially increase the efficiency of, and reduce errors in, data pre-processing and analysis, as code scripts can be created that can be re-used across different project directories with few required changes \cite{marwick2018packaging}. This practice also improves the efficiency and effectiveness of collaborations with statisticians, as it allows the researchers to share critical research project files---raw data, pre-processed data, and code scripts for extracting the pre-processed data from the raw data \cite{ellis2018share, shade2015computing}---in a single, zipped file. Further, some have suggested that if researchers learn better practices for cleanly and consistently managing project files, it will help increase they willingness to share those files and so meet standards of reproducibility \cite{marwick2018packaging}. 

One implementation of this practice is as an RStudio ``Project". In RStudio, a researcher can collect all project files in a single, structured directory and save this directory as a ``Project" \cite{rstudiousingprojects}. When the researcher opens this ``Project", RStudio is open with the working directory set to the top level of the project directory, encouraging the use of transportable relative pathnames in code that reads in and writes out data and other files from the R code. RStudio ``Projects" allow easy integration with version control tools (\textit{git}) and online platforms for sharing a directory under version control (\textit{GitHub}, \textit{GitLab}). 
While a ``Project" can have any internal
structure, a common structure can be enforced for a certain type of project
through the creation of a new ``Project" template, which defines the required
subdirectories, structure, and file names of common elements that must exist in
the project \cite{rstudioprojecttemplate}. If there is a standard for organizing files for a researcher's scientific area, this format can be encoded as a reusable template; use of the structure imposed by this template will make it easier for other researchers in the field to easily navigate code and data that is made public in efforts to increase reproducibility \cite{marwick2018packaging}. This template, when selected from a menu bar  in RStudio by a
future user, will create a new directory with a ``skeleton" structure,
potentially including templated files (e.g., for metadata that a researcher wants to remember to record for each project) \cite{rstudioprojecttemplate}.

This topic will be
covered in a \textit{Principles} module on the ``Power of using a single
structured 'Project' directory for storing and tracking research project files",
an \textit{Implementation} module on ``Creating 'Project' templates", and an
\textit{Example} module called ``Example: Creating a 'Project' template".

\textbf{4. Implementing version control.} As a research project progresses, a typical practice in many experimental research groups is to save new, renamed versions of each file (e.g., ``draft1.doc", ``draft2.doc") \cite{bryan2018excuse}, so that they can revert to earlier versions of a file. However, this practice leads to an explosion of files, and it becomes hard to track which files represent the ``current" state of a project. Version control---which tracks and documents changes to any documents that the user chooses to track in a directory---allows researchers to edit and change research project files more cleanly, keeping a single copy of each file in the directory rather than multiple versions, while maintaining the power to backtrack to previous versions. Further, with version control, ``commit messages" must be included to explain any changes, making both the changes and the reasoning behind them transparent. The use of the version control software \textit{Git} has been encouraged as a tool to enable reproducible research \cite{piccolo2016tools, ram2013git, bryan2018excuse, lowndes2017our, cetinkaya2017infrastructure}. Once a researcher has learned to use git on their own computer for local version control, they can begin using version control 
platforms (e.g., GitLab, GitHub) to collaborate with others in their research
group while keeping the project under version control \cite{bryan2018excuse, shade2015computing}. Projects saved in a single, structured directory
can be easily put under \textit{Git} version control in \textit{RStudio}, which
includes a pane that allows users to work under version control without learning
command-line version control language and, if desired, easily connect the
project with an online version of the project hosted on \textit{GitHub}. These platforms allow
the all collaborators to share a current version of a project directory 
(similar to Dropbox), but in a way that allows easy use of version control 
and that is more efficient for exploring (and, when necessary, undoing) the changes 
each team member has made to project files \cite{bryan2018excuse}.

For many years, using \textit{Git} version control required use of the command line,
limiting its accessibility to researchers with limited programming experience.
Graphical interfaces, however, have removed this barrier, and RStudio has 
particularly user-friendly tools for implementing version control. At CSU, we have found that Git and GitHub can be taught fairly quickly to researchers in their first programming course, so that they can successfully use GitHub to submit class assignments when taught through the RStudio / GitHub interfaces; others have had similar success at other institution \cite{bryan2018excuse}.

This
topic will be covered in two \textit{Principles} modules called ``Harnessing
version control for transparent data recording" and ``Enhance the
reproducibility of collaborative research with version control platforms" as
well as an \textit{Implementation} module on ``Using git and GitLab to implement
version control". A key reading in this section will be \cite{bryan2018excuse}.

\underline{\textbf{Improving the Reproducibility of Experimental Data
Pre-Processing}}

The second sequence will provide principles and tools for increasing the
computational reproducibility at an early stage of biomedical research, as
experimental data is pre-processed. By ``pre-processing", we mean the steps 
taken to convert data from the raw data---either collected by hand or output
by laboratory equipment---into a format ready for data analysis. We will focus
particularly on improving the reproducibility of this step for complex 
raw data output by laboratory equipment, for example feature identification 
and quantification in mass spectrometry data, gating in flow cytometry data, 
image pre-processing for functional magnetic resonance imaging (fMRI), as well
as general pre-processing steps like normalization and scaling. This sequence will include nine modules covering three main topics: 

\textbf{1. Using code scripts to pre-process experimental data.} The experimental data collected for biomedical research often requires 
pre-processing before it can be analyzed (e.g., gating of flow cytometry data, 
peak finding and quantification for LC / MS metabolomics data). While 
proprietary point-and-click software is typically available for this pre-processing,
use of such software can limit the transparency and reproducibility of this 
pre-processing stage of the analysis and is 
time-consuming for repeated tasks over large research projects. Point-and-click software is used interactively and often does not create a history of steps and choices, at least not in a format that is easy for a statistician to navigate, understand, and check \cite{peng2011reproducible, pernet2015improving}. Statisticians have clearly stated that, to ensure research is reproducible and that a collaboration is efficient, they would like to receive raw experimental data (e.g., the direct output from experimental equipment), the processed data (preferably in a 'tidy' format), and an ``explicit and exact recipe" for how the processed data was derived from the raw data \cite{ellis2018share}.

A code script, like an R script, provides this ``explicit and exact recipe" to describe how raw data was pre-processed. While many of the pre-processing tasks required for biomedical experimental data are complex (e.g., feature identification and quantification, gating), R has package extensions that can be used for these tasks, many hosted on Bioconductor \cite{huber2015orchestrating}. Scripted pre-processing can help reduce the temptation to manually edit data, including manually changing file formats, during pre-processing, which prevents reproducibility and impedes transparency \cite{pernet2015improving}. It can also improve the efficiency of pre-processing, as scripts can often be re-used with minimal changes for data from new experiments \cite{pernet2015improving}---while laboratory-based researchers must invest time to learn some programming to be able to use scripts for pre-processing, this time investment is rewarded by a substantial improvement of the efficiency of future pre-processing tasks. 
Open-source scriptable
software tools bring other key advantages compared to proprietary software in terms of data
pre-processing, including that open-source choices are transparent and often more robust and easier to extend \cite{cetinkaya2017infrastructure, huber2015orchestrating,
preeyanon2014reproducible, piccolo2016tools, baumer2017lessons}. 
Training is needed for laboratory-based biomedical researchers on the use of these tools, and how they can improve transparency and reproducibility, for researchers new to programming. Expertise
with a scripting language is not universal across biomedical researchers,
although literacy in programming is increasing in the sciences
\cite{ram2013git}, and many now recommend programming as a critical skill for
all biology Ph.D. students \cite{list2017ten}. 

This topic will be covered in one
\textit{Principles} module on ``Principles and benefits of scripted
pre-processing of experimental data" and two \textit{Implementation} modules
called ``Introduction to scripted data pre-processing in R" and ``Simplify
scripted pre-processing through R's 'tidyverse' tools".

\textbf{2. Working with complex data types during pre-processing.} Many R functions output data in a form that is ``untidy" \cite{robinson2014broom}, in the sense that it does not comply with the structured ``tidy" format required by R's \textit{tidyverse} tools \cite{wickham2014tidy}. This is particularly true for raw data from many biomedical experiments, especially machine-generated data (e.g., output from a flow cytometer or mass spectrometer). Further, Biocondutor, which hosts many R packages useful for preprocessing and analyzing experimental biomedical data, relies heavily on an object-oriented framework, with functions outputting data in S4 object formats \cite{gentleman2004bioconductor}.  This aids interoperability among Bioconductor packages and helps collect different types of data from an experiment (e.g., expression measurements, phenotypes, and administrative data from an experiment) \cite{gentleman2004bioconductor}, but these S4 objects are 'untidy', in the sense that they do not follow the format required for 'tidyverse' R tools \cite{biobroom} While these formats are well-justified within open-source software for pre-processing complex biomedical data, they add a critical barrier for researchers wishing
to implement reproducibility tools, especially tools from the popular and user-friendly 'tidyverse' collection of R package extensions \cite{robinson2014broom}. This hurdle can be surmounted by skilled R programmers, but it creates a barrier for researchers who are learning scripting tools \cite{robinson2014broom}, and it can reduce transparency of analysis by requiring obscure, lengthy code to extract and tidy data from the complex data object \cite{robinson2014broom}. Very recently, the \textit{broom} and \textit{biobroom} R packages have been developed 
to extract a 'tidy' dataset from many common complex data formats that are output by R functions, including much of the output formats common for preprocessing biomedical experimental data \cite{robinson2014broom, biobroom}.
These tools create a clean, simple connection between the complex data formats
often used in pre-processing experimental data and the 'tidy' format
required to use the 'tidyverse' tools now taught in many introductory R courses, making it more straightforward for a researcher new to R programming develop a scripted R workflow from data preprocessing through to data analysis and visualization using 'tidyverse' tools. The \textit{biobroom} package, in particular, can 'tidy' data within many popular Bioconductor data formats, including \textit{ExpressionSet} objects \cite{biobroom}. This topic will be covered in a \textit{Principles} module on ``Complex data types in
experimental data pre-processing", a \textit{Implementation} module on ``Complex
data types in R and Bioconductor", and an \textit{Example} module called
``Example: Converting from complex to 'tidy' data formats".

\textbf{3. Reproducible data pre-processing protocols.} Pre-processing software allows many parameter choices, which can lead to an explosion of possible combinations of parameter choices in pre-processing data \cite{munafo2017manifesto, shade2015computing, pernet2015improving}. To ensure transparent and high-quality biomedical research, it is important to be thoughtful in selecting the parameter values, and to keep a detailed record of which parameter values were selected and why throughout pre-processing. Ideally, a research group should maintain ``protocols" describing this pre-processing that are as detailed and reproducible as the experimental protocols they maintain  \cite{gentleman2004bioconductor}. Creating and maintaining such \textit{data pre-processing protocols} helps make it easier and clearer for laboratory-based researchers to share the pre-processing ``recipe" with collaborators and as part of publishing a journal article that meets reproducibility guidelines. It also helps ensure a continuity of methods across a research group, where a research laboratory can be sure the same pre-processing is maintained as researchers join and leave the group \cite{shade2015computing}.
Reproducibility tools can be used to create reproducible data pre-processing protocols---documents that combine code and text in a ``knitted" document, which can be re-used to ensure data pre-processing is consistent and reproducible across research projects. The R extension package RMarkdown can be used to create documents that combine code and text in a 
``knitted" document, and it has become a popular tool 
for improving the computational reproducibility and 
efficiency of the data analysis stage of research. This tool can also be used earlier in the research process, however, to improve reproducibility of pre-processing steps. 
This topic will be covered in a \textit{Principles} module called ``Introduction to reproducible data pre-processing protocols", an \textit{Implementation} module on ``RMarkdown
for creating reproducible data pre-processing protocols", and an
\textit{Example} module called ``Example: Creating a reproducible data
pre-processing protocol". 

\underline{\textbf{Choice of tools to include in ``Implementation" modules.}}

To improve reproducibility practices among our target audience of laboratory-based biomedical researchers, it is important
that we provide them with some instruction on how to implement the
reproducibility principles presented. For some of these principles, there are
several reasonable and well-developed tools that could be used for
implementations. However, few researchers are interested in learning every tool,
and instead would prefer to learn one set of tools that ``just work", and presenting a single set of tools improves the chance of trainees mastering the tools \cite{brown2018ten}. 

We have chosen for the implementation portion of these
modules to focus on tools from the open-source R programming language. R can be
freely, quickly, and easily downloaded and installed to a user's computer,
allowing new users to get started quickly, a critical consideration for usable
scientific software \cite{list2017ten}. R has been maintained for over a decade
by the R Development Core Team and works with all major computing platforms,
ensuring  widespread access, stability, and compatibility, also critical for
ease-of-use \cite{baumer2017lessons, altschul2013anatomy}. R offers a
well-developed environment for creating new tools that extend the core language
\cite{wickham2015r, gentleman2004bioconductor} and includes ample tools for documenting research workflows
\cite{xie2015dynamic, xie2016bookdown}. R's status as a common tool among statisticians and biostatisticians means that its use in early stages of
experimental data recording and pre-processing can help foster closer
collaborations between laboratory-based scientists and statisticians throughout
the research process. R can be scaled as the volume of data in projects grows
\cite{list2017ten}, as it includes tools to interface with distributed computing
platforms (e.g., \textit{Hadoop} \cite{pathak2014rhadoop}, \textit{Spark}
\cite{sparklyr}), and its scripts can be integrated within workflow management
systems (e.g., \textit{Galaxy} \cite{goecks2010galaxy, walker2016models}). RStudio is a free, open-source Integrated Development Environment (IDE) for the R programming language. It is actively developed by a team of some of the best R programmers worldwide, including the developers of the ``tidyverse" (including the \textit{ggplot2} plotting system), the most popular tools for literate programming in R (\textit{knitr} and \textit{RMarkdown}) and the Shiny web application system. Some
of the implementation tools---git and GitLab, for example---are separate from R
but can be mastered much more easily if trainees are taught to use them through
RStudio's user-friendly interfaces rather than using the command line or other
alternative interfaces. 

% We have also selected to focus on this set of tools for
% the \textit{Implementation} modules because two members of our team (Anderson
% and Lyons) use R daily for their own research and so are able to provide much
% better instruction and details on using this set of tools than alternative tools
% for the same tasks. Dr. Anderson also regularly teaches students in her
% department how to use this set of tools through a graduate-level course and has
% developed techniques for helping students new to programming to master R using
% the RStudio interface, including using RStudio's interface to use RMarkdown,
% track a project under git version control, and connect to version control
% platforms to improve collaborative work. 

We appreciate that many laboratory-based biomedical researchers do not know the R language, and
some of them may want to learn more about improving reproducibility without
needing to learn a new programming language. For this reason, we have
deliberately separated the ``Principles" and ``Examples" content in our modules
from the ``Implementation" modules, so that a researcher can select a track of
our modules that does not require programming knowledge. Further, while all of
the ``Implementation" modules are conceptually focused on tools that an R
programmer would use, several of the modules could be appreciated and used to
improve reproducibility without a mastery of R. For example, RStudio and its
``Projects" functionality can be used to help manage research project files,
keep them under version control, and interface with GitLab without using any R code within the project. Similarly, while
the ``tidy" data format is currently an important implementation common within R
for structuring data, understanding its principles and characteristics does not
require any knowledge of R. In our table of example ``tracks" that a trainee
could follow (Table \ref{tab:tracks}), the track we give for an example Principal Investigator is one example
of a track that would not require prior knowledge of R or other programming
languages.   

\input{tables/module_content_data_recording.tex}

\input{tables/module_content_data_preprocessing.tex}

\input{tables/module_tracks.tex}

\subsubsection*{Format for the training modules}

\textbf{Online book.} We will use an online book to collect all the training
materials in a single structure. Each chapter of the book will contain all the
materials from one of the modules listed in Tables \ref{tab:content_one} and
\ref{tab:content_two}, for twenty chapters total. We have created a prototype
(Figure \ref{fig:prototype}) to demonstrate some features of the final book.
Users will be able to quickly navigate through chapters with a navigation bar on
the left of the webpage, with chapter subsection links opening when a chapter is
selected. We will embed the lecture video at the start of the chapter, allowing
a user to watch the video content without leaving the book website, which
prevent having to ``hop around" online to watch the video and then access
written text and additional educational materials in the book. This type of format, 
in which video content is woven into written and additional materials, has been
praised as an effective format for presenting online training materials \cite{searls2012online}.

The book will
include a link for the trainee to download a copy as a PDF or EPUB file, to use
as a future reference offline if desired. The format also includes buttons that
can be used to share the link to the online book with others through Twitter and
other platforms, as well as a link to the book's GitHub repository, to allow
early users of the in-development materials to provide feedback on typos, broken
links, unclear materials, and other issues to iron out as we develop the
materials. 

We will create this online book using the \textit{bookdown} framework
\cite{xie2016bookdown}. This in an innovative framework that will allow us to
create a searchable online book that weaves R code into the text and that can
include embedded tutorial videos, active web links to online references, and
computationally reproducible practice examples and exercises. Further, by
including R code examples as executable code, we will be able to use this online
book to frequently check tutorial code examples to quickly identify and fix any
broken tutorial code \cite{xie2016bookdown}. We will use GitHub's Git Pages to
freely post this book online. Dr. Anderson (PI) has previously created two
\textit{bookdown}-based books, \textit{R Programming for Research} and
\textit{Mastering Software Development in R}, and has posted and maintained
\textit{R Programming for Research} online continuously since Fall 2016 through
Git Pages.  

\textbf{Video lectures.} ``Video lectures have many advantages: a sense of immediacy, the feeling of a personal touch, helpful emphasis and nuance in the presentation, and the simple fact that a memorable professor makes for memorable subject matter. In such skilled hands, the video format affords the use of techniques that have been shown to enhance learning, including not only visual material but also expressions of enthusiasm by the lecturer and even humor [2]." \cite{searls2012ten}
Each chapter will include a video lecture that covers
the module's material, with the approximate length of each lecture listed in
Tables \ref{tab:content_one} and \ref{tab:content_two}. We will record these
video lectures in CSU's Computer Assisted Teaching Support laboratory (see
letter from Dr. West), which includes equipment and staff for creating
professional-quality video lectures. We will use YouTube to freely host these
videos and embed the video within the text of that module's chapter in the
online book (see Figure \ref{fig:prototype} for an example of how this will look
to trainees). Trainees will be able to watch each of these videos without
leaving the online books webpage, while hosting them through YouTube will allow
us to take advantage of their excellent, free, and well-tested platform for
sharing videos, as well as allow us to collect detailed analytics on how often
each video is watched and for how long, to help us assess the use of this
component of the training material. 

\textbf{Additional educational materials.} Each module will contain additional
educational material, to help the trainee absorb the material and assess his or
her mastery of the topics. Depending on the module, this additional content will
either be a quiz, questions for discussion, or an applied exercise to try out
the implementation of a tool or principle covered in the module (see Tables
\ref{tab:content_one} and \ref{tab:content_two} for the specific material
planned for each module). For many of the \textit{Implementation} modules, these extra educational materials will be applied examples, since providing tutorials, example code, and example datasets can substantially improve the ability of new users to learn software tools \cite{list2017ten, searls2012ten, via2011ten}, while including quizzes within training content help trainees self-evaluate their mastery of the material \cite{searls2012ten, via2011ten}. To help engage trainees, we will include audio and
video content walking the trainee through answers and solutions for these
additional materials. While not a substitute for in-person training, these video
and audio discussions of the materials is meant to mimic the detailed
walk-throughs and discussions that we would do after a student attempted these
materials if we were teaching these materials in person. We will tape the video
and audio content in CSU's Computer Assisted Teaching Support laboratory (see
letter from Dr. West). We will host the video content through YouTube and the
audio content through SoundCloud and embed this content in the online book, as
with the video lectures. We will use Google Forms as a free and unlimited way
for us to create the quizzes and embed them in the online book [ref].

\noindent \textbf{Insuring compliance with Rehabilitation Act.} We have plans
for making our proposed training module section 508 compliant of the
Rehabilitation Act (29 U.S.C. '794 d), as amended by the Workforce Investment
Act of 1998. Much of the online content will be text based. For figures and
other images in the book, we will use \textit{alt} and \textit{longdesc} attributes
within the image tag to provide a text alternative. Using YouTube to host the
lecture videos will allow us to draw on their functionality for accessibility,
including ``enough time" requirements in terms of being able to pause and turn
off the content. YouTube allows users to add and edit closed caption content on
their videos, which we will use to add optional closed captions to this
content---in addition to improving accessibility of the content, it may also
help trainees for whom English is a second language to follow the content. In
the first two years of the grant, we will have a student hourly who will assist
Dr. Anderson in the technical implementation of the online book, and helping to
ensure the content is compliant with the Rehabilitation Act will be one of her
key tasks. If this task requires the use of interesting techniques or
technologies, Dr. Anderson and the student may prepare a journal article
describing these techniques and submit it to \textit{The R Journal} during the
project period. The R community is very open to and interested in improving
accessibility, as evidenced by previous publications, presentations, and
software on these topics (e.g., \cite{uswebr, godfrey2013statistical}).

\subsection{Team}

\input{tables/team_description.tex}

Our team (Table \ref{tab:team_description}) combines experts in R programming (Anderson, Lyons), including its use
to improve the computational reproducibility of health-related research, with
laboratory-based academic researchers in Microbiology and Immunology
(Henao-Tamayo, Gonzalez-Juarrero, Robertson) who are \textbf{attuned to the
needs of and barriers to improving the reproducibility of experimental data
collection and pre-processing among laboratory-based biomedical researchers}.
Our team will allow us to develop training modules that present state-of-the-art
approaches and tools for reproducibility, but do so in a way that is prioritized
to be most useful and accessible to health researchers whose training has
focused on laboratory-related, rather than computational, methods, and for whom
existing training materials on computational reproducibility might be hard to
understand or apply to their own research projects. 

\noindent Our team will also include a to-be-named undergraduate student hourly and Dr. Julie Maertens (Research Associate), a senior evaluator
at the Colorado State University STEM Center, which assists and collaborates
with faculty involved with STEM education-based research and programming in
designing and carrying out evaluations. The student hourly will assist Dr. Anderson
in the technical work of publishing the content our team develops in an online book. 
Dr. Maertens will assist in the design and
implementation of project evaluation throughout this project. Dr. Maertens will
only be involved in the project to assist in planning and implementing
evaluation, and her percent effort is capped at 0.85\% to reflect the RFA's
budget restriction of \$3,000 total on program evaluation, including salary
support.

\subsubsection*{Coordination and management of the team}

\input{tables/team_roles.tex}

The Principal Investigator and all four Co-Investigators will collaborate to 
develop the materials in the training modules. We have designed a plan (Table \ref{tab:roles}) in which, for each module, Dr. Anderson and one of the Co-Investigators will collaborate as the primary authors of the written text, lecture slides, and additional education materials (quiz, discussion questions, or applied exercise). A second co-investigator will serve as the first tester of the module and will work through the module material and provided detailed feedback to the two authors of the module for refining the material. The training materials for the module will then be tested on the next CSU pilot testing session (sessions will occur twice per year over the project period), and further refined based on that feedback, feedback from the two Co-Investigators who did not have the roles of author or first tester for that module, and any feedback from early online users. Dr. Anderson will then film the video lecture for the module. Throughout the project period, Dr. Anderson and the four Co-Investigators will meet as a group bi-monthly to check in on progress on the project. 

Throughout the module development period (first two years of the project), Dr. Anderson and the undergraduate student will transfer the developed training content into the online book format and publish it online. Dr. Maertens will assist Dr. Anderson at points throughout the project period to develop materials for evaluation, including feedback surveys to use with CSU pilot testers, survey questions to include in the online book for evaluation purposes, and brief training on how to best elicit qualitative feedback from pilot testers during the biannual CSU pilot testing sessions.

Our plan of content development and publishing is ambitious, but we are
confident we can meet it. Dr. Anderson previously developed the online content,
in collaboration with a co-instructor, for a five-course specialization with
approximately twice as much content in under nine months. She has experience
developing and publishing online training materials for learning R-based tools,
including through the \textit{bookdown} online book framework we plan to use
here. In this previous development of online training materials, Dr. Anderson
learned to collaborate closely with co-authors in developing and refining the
content and in developing quizzes and applied exercises to allow trainees to
test their understanding of the content. She will bring that experience in the
proposed project, to help organize and integrate the contributions of our team
of co-investigators. For the technical development of the book, she will be
assisted by and supervise an undergraduate hourly during the first two years of
the project, to help in turning the intellectual content that she and the
co-investigators develop into the formatted online book. She will work with Dr.
Maertens to solidify and implement evaluations of the training materials.

\subsection{Institutional Environment and Commitment}

Colorado State University is a Research-I institution, with vibrant research programs in a variety of scientific, engineering, and health-related fields. As Colorado's land-grant university, CSU has a 100-year-old extension program to help researchers disseminate their research results to members of the wider community. Colorado State University is very supportive of improving the reproducibility of
research, and it offers ample resources that will help us ensure the success of
the proposed project. \textbf{Our institution has clearly expressed its support
for our proposed effort to create, refine, evaluate, and disseminate these
training materials} in institutional letters of support from Dr. Jac Nickoloff
(Chair of the Department of Environmental \& Radiological Health Sciences, CSU),
Dr. Dean Gregg (Chair of the Department of Microbiology, Immunology, \&
Pathology, CSU), and Dr. Alan Rudolph (Vice President for Research, CSU). As
expressed in the letter of support from Dr. Nickoloff, Dr. Anderson's teaching
expectations during the project period are capped at three courses every two
years, allowing adequate time for her to complete the tasks required by this
proposal. As also expressed in that letter, Dr. Anderson's department supports
that the training materials developed under this grant will be made freely
available through online publication under a Creative Commons license. Dr.
Anderson's department has supported her previous development and publication of
similarly free and open training materials following a similar format [ref].

Colorado State University is host to a large number of laboratory-based
biomedical researchers, especially in fields related to drug and vaccine
development for infectious diseases. We will \textbf{take advantage of this
environment} to help us pilot test and refine the training materials, to ensure
they are clear, relevant, and useful to our target population of
laboratory-based biomedical researchers. We have received statements of support
from relevant programs, including the the director of the CSU Interdisciplinary
Graduate Program in Cell \& Molecular Biology, and Associate Director of the
Interdisciplinary NSF-NRT GAUSSI training program in Computational Biology, to
help disseminate our materials to pilot testers and early users of our training
materials within CSU (see letters from Drs. Dean Gregg, Carol Wilusz, and Jeff
Wilusz). 

Colorado State University offers many excellent facilities that we will take
advantage of to help us achieve our project's goals. CSU provides meeting rooms
that we can reserve free-of-charge to use for the CSU-based user testings. The
Computer Assisted Teaching Support (CATS) laboratory at CSU's Academy for
Teaching and Learning has professional-grade recording equipment that we will
use to record the video lectures within each module (see letter from Dr. Andrew
West). CSU's STEM Center will provide help in evaluating the training modules,
including through the budgeted involvement of Dr. Julie Maertens, a senior
evaluator at the center. 

\subsection{Piloting and evaluating the effectiveness of the training modules}

\begin{quotation} ``Applications must include a plan for evaluating the
activities supported by the award in terms of their \textbf{frequency of use}
and their \textbf{usefulness}. The use of \textbf{multiple evaluation
approaches} is highly encouraged as is \textbf{testing several groups with
different characteristics}. The application must specify \textbf{baseline
metrics (e.g., numbers, educational levels, and demographic characteristics of
test group)} in a structured format, as well as \textbf{measures to gauge the
short and long-term success of the research education award in achieving its
objectives}. Applicants are expected to \textbf{obtain feedback from test group}
to help identify weaknesses and to provide suggestions for improvements, and
\textbf{make the evaluation and feedback data} available to NIGMS staff."
\end{quotation}

\input{tables/evaluation.tex}

We will use [x] different methods for pilot testing and evaluating these materials: ... We expect that these different methods will allow us to collect different sets of 
feedback on the frequency of use and usefulness of the training materials (Table \ref{tab:evaluation}), providing a rich collection of ideas for us to use in refining the materials. Examples of what we hope to learn from each group in pilot testing and evaluation (Tables \ref{tab:evaluation}). For each of the modules, we have outlined learning objectives will help us evaluate if the training modules are useful in achieving their educational goals (Tables \ref{tab:content_one} and \ref{tab:content_two}).

\textbf{Biannual CSU pilot testing sessions.}
We will conduct two, day-long pilot testing sessions at CSU in each year of the
project. The CSU user testing groups will consist of current and future
laboratory-based biomedical researchers. We will recruit trainees with a variety
of research roles, including undergraduate students, graduate students,
postdoctoral fellows, research associates, and principal investigators. We have
informed several CSU biomedical researchers about these proposed testing
sessions and received their support in encouraging CSU researchers within their
groups and departments to participate (see letters from ...). 

In the first two project years, each session will test the set of modules
developed since the last user testing (approximately five modules will be tested
each of these session). The sessions will begin with our team giving live
lectures of the same content we plan to film for the video lectures included in
the online book. This will allow us to improve and refine this content, based on
detailed feedback from testers representative of our target audience, before
filming the final video lectures. During the rest of the session, we will divide
the trainees into small teams to work through the additional educational
materials (applied exercises, quiz questions, and discussion questions) to iron
out problems with the clarity or implementation of these materials. The trainees
will have access to the in-development online book as they work through these
materials. In the last year of the project, these sessions will revisit the material
in modules that proved problematic in their first round of pilot testing, allowing us
to re-test approximately ten of the modules (five tested per session in project year 3). [We can ask these pilot users many questions, both before and after the pilot testing. Further, we will have access to ask them longer-term outcomes, as well as to ask at the department level how the use of these training materials by a number of people in the department has changed research practices and what is considered ``best practice" for research in the department (i.e., a `bubble up" effect).]

Dr. Anderson (PI) has experience in productively conducting these kinds of user
testing sessions at CSU. She has run several two-hour user testing sessions with
students from various departments of Colorado State University prior to
releasing R software packages \cite{futureheatwaves, countyweather}. Further, in
April 2016, she led a longer, two-day user testing session through a Weather
Data Hackathon at Colorado State University (Figure \ref{csu-r-hackathon}).
Around 15 people participated, including undergraduate students, graduate
students, postdoctoral fellows, and professors from CSU's Departments of
Atmospheric Sciences, Civil \& Environmental Engineering, Microbiology, and
Statistics. Some of the ideas and code developed during this Hackathon have
since led to development and publication of open source software
\cite{countyfloods, noaastormevents}.

\begin{SCfigure} \centering \includegraphics[width =
0.6\textwidth]{figures/csu_hackathon.png} \caption{Some of the approximately 15
undergraduate students, graduate students, postdoctoral fellows, and professors
who participated in a two-day Weather Data Hackathon at Colorado State
University in April 2016 led by Dr. Anderson.} \label{csu-r-hackathon}
\end{SCfigure}

\textbf{Participants in American Society for Microbiology pre-conference workshop.} [For these people, we could definitely do a survey before to get information on demographics, education level, interest in the training materials, etc. We could also do a post survey to find out what they learned, how helpful it was, what they found confusing, etc. Finally, we could get their email addresses to ask some longer-term evaluation questions (e.g., How are they using what they learned 1--2 years after taking the workshop? How much did they retain in terms of principals, implementation, and examples?). We can also use questions that are asked during the workshops and areas where additional materials (applied exercises, quizzes, discussion questions) are problematic to help us hone our training materials.]

\textbf{Trainees who access and use the online book and embedded materials.}  We will plan to develop and post the text and some of the additional educational materials (e.g., quizzes, discussion questions) online through GitHub \textit{as we write the book and develop the materials}. We will use social media to invite people to try out the book as we develop it. Based on previous work developing online books, we have found that this open development process can help attract users very early in the process, and that these users are often very helpful in providing feedback as the book is developed. We will elicit their feedback through GitHub (``Issues" page will be the main forum for them to post comments and suggestions). [These could potentially be from anywhere in the world, and for many we won't have great ways to contact them.]

\begin{itemize}
\item Google Analytics for online book's website.
\item YouTube analytics for the embedded videos. 
\item Quiz for some modules. Use to evaluate how well they've mastered the material. Use Google Forms to embed these quizzes.
\item Link to voluntary survey in each chapter of the online book: Educational level, demographic characteristics. Includes rating for the usefulness of that module.
\end{itemize}

\textbf{Non-CSU pilot testers.} All same as the online testers, plus some more detailed qualitative information.

\subsection{Dissemination Plan}

We will use GitHub's free ``Pages" website hosting to publish the book freely online, with all materials published under the Creative Commons Attribution-ShareAlike 4.0 International License [ref], \textbf{making all materials freely accessible, both nationally and internationally}. From the beginning of the project, we will publish the book online as it develops, and we will promote this material through postings on social media (e.g., Twitter) and take advantage of our network of colleagues in biomedical research and the R programming community to help promote the availability of the materials (for example, see letter of support from Dr. Peng). This book will be hosted on a ``Git Pages" webpage, allowing the online book to be easily accessed through a link posted on the NIGMS's \textit{Clearinghouse for Training Modules to Enhance Data Reproducibility}. There will be no paywall or other restriction on accessing any of the training materials, and source code for the book and exercises will be published on GitHub. All video and audio content will be published online in free formats through YouTube and SoundCloud, with the content embedded in the online books webpage. At the end of project years 2 and 3, we will also post a static version of the book to the website \textit{bookdown.org}, where people can go to find free online books published using the bookdown format and which invites direct submissions from authors that have used these framework. The PI has previously had substantial success in disseminating online training materials. She is the co-instructor of a five-course specialization on \textit{Mastering Software Development in R} through the Massive Open Online Course platform Coursera. This series has had over 50,000 participants since it was opened in Fall 2016, and an accompanying online book on the LeanPub platform has been downloaded by over 14,000 people.

In addition to these methods of disseminating the training materials to a general audience, \textbf{we will also take specific steps to make sure that our target audience---laboratory-based biomedical scientists---are aware of these training materials.} We will apply to present posters or oral presentations in years 2 and 3 of the project at three national and international conferences (American Society for Microbiology Conference, American Association of Immunologists Meeting, and International Society for the Advancement of Cytometry) to pilot the training materials and help get out the news among our target audience that these materials are freely available. We will also apply to present a workshop in year 2 of the project at the American Society for Microbiology Conference to pilot the training materials and help get out the news among our target audience that these materials are freely available. We will pilot our training materials among CSU researchers in our target audience through biannual, day-long user testing; in addition to providing us with feedback to help refine our materials, this will help us let members of our target audience know that these training materials are freely available and how to find them. We will also invite colleagues (and their research group members) at outside of CSU to serve as early pilot testers of the online version of all our materials. In addition to providing us with feedback to help refine our materials, this will help us let members of our target audience know that these training materials are freely available and how to find them. Finally, we will write and submit a paper describing these training materials and highlighting their content in a biomedical journal relevant to our target audience, like [example of a couple of journals].

\clearpage

\subsection{Timeline}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.94\textwidth]{figures/timeline.pdf}
    \caption{Timeline for proposed activities for this project.}
    \label{fig:timeline}
\end{figure}

\clearpage

\bibliographystyle{unsrtnat}
\bibliography{rep_modules}

\end{document}

\documentclass[pdftex,english,11pt,parskip=half]{scrartcl}
\usepackage{palatino}
\usepackage{mathpazo}
\usepackage[margin=0.55in]{geometry}
%\usepackage{parskip}
\usepackage[compact]{titlesec}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{babel}
\usepackage{framed}
\usepackage{wrapfig}
\usepackage{subfig}
\usepackage{sidecap}
\usepackage[labelfont=bf,font=small,format=plain]{caption}
\usepackage{doi}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage{array}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{float}
%\usepackage[authoryear]{natbib}
\usepackage[numbers]{natbib}
\usepackage{url,hyperref,color}
\usepackage{rotating}
\usepackage{lscape}
\definecolor{darkblue}{rgb}{0.0,0.0,0.75}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}
\newcommand{\fixme}[1]{{\color{red} #1}}
\renewcommand\thesection{\Alph{section}}
\renewcommand{\familydefault}{\sfdefault}
\newcommand{\tabitem}{~~\llap{\textbullet}~~}
\begin{document}
\addtokomafont{section}{\large}
\def\bf{\normalfont\bfseries}
\pagestyle{empty}

\section*{Research Education Program Plan}

\section{Significance}
\vspace{-0.1in}

The recent NIH-Wide Strategic Plan \cite{nih2016strategic} describes an
integrative view of biology and human health that includes translational
medicine, team science, and the importance of capitalizing on an exponentially 
growing and increasingly complex data ecosystem \cite{nih2018data}.  Underlying 
this view is the need to use, share and reuse biomedical data generated from widely 
varying experimental systems and researchers. Basic sources of biomedical data range 
from relatively small sets of measurements, such as animal body weights and bacterial 
cell counts that may be recorded by hand, to thousands or millions of instrument generated 
data points from various imaging, -omic, and flow-cytometry experiments. In either case, 
there is a generally common data or information workflow (Figure \ref{fig:workflow}) that proceeds 
from measurement, to data recording, pre-processing, analysis, and interpretation 
\cite{}.  However, the distinct actions of data recording and data pre-processing are often 
merged or combined as a single entity using commercial or open source spreadsheets.  Such 
spreadsheets include various levels of meta-data, including filesystem data that determines 
reading and writing operations by the software environment in which it runs, together with multiple 
experimental data types and units recorded in sometimes complicated arrangements of tables, 
charts, notes, and other figures.  Additionally, and especially for instrument generated data sets, 
these spreadsheets are often used to pre-process the data with black-box statistical calculations 
and graph generating 
functions that are combined with the primary or raw experimental data.  It is also widely 
known and discussed among data scientists, mathematical modelers, and statisticians 
\cite{krishnan2016towards}, that there is a frequent need to discard, transform, and 
reformat various elements of these spreadsheets in an often labor intensive and error 
prone process of ``data cleaning'', in order to apply more advanced computational methods 
and to integrate the data with other analysis and visualization platforms.

\textbf{Here, we identify the clear separation between data recording and data pre-processing 
as a critical point for enhancement of data reproducibility.} Such a rigorous demarcation requires 
some change in the conventional understanding and use of spreadsheets, and a recognition by 
biomedical researchers that recent advances in computer programming languages, especially the 
R programming language, provide user-friendly and accessible tools and concepts that can be 
used to build on their existing methods to implement a transparent and reproducible data workflow. 
As a wholesale adoption of these concepts and software tools may be disruptive to established 
laboratory procedures, the 
approach in this proposal is to provide training modules that can be adopted as appropriate 
for a wide range of individuals with differing roles within small and large research groups.  
General principles and guidelines are presented separately from implementation and examples. 
Additionally, the training modules will be developed on-site with NIH-funded microbiology 
and immunology labs devoted to anti-tuberculosis drug and vaccine development. 
\textbf{Our ultimate educational goal is introduce the language, concepts, and tools of R-based 
``tidy'' data structures to the laboratory bench scientist whose attention is rather to their 
experimental technique and collection of accurate data, and who may have little or no background 
in the use of general purpose software tools.} While this proposal uses examples from microbiology 
and immunology experiments, the collection of primary data in a flexible, open source, 
transparent, and reproducible format or data structure that can be kept in it's primary state 
without the need for additional modification, is a solution that extends throughout large and 
small scale biomedical science projects. 

\begin{figure}[ht] \includegraphics[width =
\textwidth, trim={0 9cm 0 3cm}, clip]{figures/workflow.png} 
\caption{Data workflows with spreadsheet-combined data recording and pre-processing, 
and separation of data recording and pre-processing using a  ``tidy'' data structure.} 
\label{fig:workflow} \end{figure}


\section{Innovation} \vspace{-0.1in}

\textbf{We will use the
innovative \textit{bookdown} framework \cite{xie2016bookdown} to structure and
publish all of our training materials as a free and open online book, with embedded video lectures and additional educational materials}. The
\textit{bookdown} framework has been available for a little over two years and
extends the principles of \textit{Rmarkdown} \cite{xie2015dynamic} to allow authors to create attractive
online books that integrate programming code and text. With this format, code examples and related
output do not need to be copied and pasted into a document, but instead is
automatically generated. Through this innovative framework, we
will create a searchable online book that weaves R code into the text
and includes embedded video lectures, active web links to online
references, and computationally reproducible examples and exercises
(Figure \ref{fig:prototype}). Further, trainees will be able to
download the book as either a PDF or EPUB file, to use as a reference as they
continue learning to implement reproducibility tools in their research projects. Even though this framework is new, it has proven
itself reliable and effective---it serves as the framework for several extremely
popular and highly-accessed books on R programming, including the extremely popular book \textit{R for Data
Science} \cite{wickham2016r}. 

\begin{figure}[t] \includegraphics[width =
\textwidth]{figures/book_prototype.jpg} \caption{Prototype of online course
book, with features highlighted.} \label{fig:prototype} \end{figure}

Dr. Anderson (PI) is an early adopter of the \textit{bookdown} framework and served as an expert reviewer for \textit{bookdown: Authoring Books
and Technical Documents with R Markdown} \cite{xie2016bookdown}. Since
the \textit{bookdown} framework became available, she has used it to create two openly-available online
books: the \textit{R Programming for Research} online coursebook (https://geanders.github.io/RProgrammingForResearch/), which she uses
as a joint textbook and website for the \textit{R Programming for Research}
course she teaches each fall at Colorado State University, and \textit{Mastering
Software Development in R} (https://bookdown.org/rdpeng/RProgDA/), which she co-wrote with Dr. Roger Peng as a manual
for developing advanced R programming skills and which has been downloaded by
over 14,000 people from LeanPub (see letter from Dr. Peng). 

\textbf{The use of this framework will help us effectively reach a large
audience of laboratory-based biomedical researchers in need of training materials to improve the reproducibility of data
recording and pre-processing.} We will 
post this book online using the \textit{GitHub Pages} \cite{gitpages}, as we have done
with a previous book created with the same framework \cite{andersoncoursebook}. This will allow anyone to
freely access this content online. We will publish both the current version of the developing book and its underlying code openly online from the beginning
of our development of the training materials. \textbf{By making the training
materials available from day one, as they are developed, we will be able to
attract early users to help disseminate the material as it evolves and also be
able to get early feedback.} Once the online
book is developed, we will submit a static version of it to be posted
on the homepage of the \textit{bookdown.org} website \cite{bookdownorg}, providing
another way for our key audience of laboratory-based biomedical researchers to find and access the materials.

\section{Approach---Proposed Research Education Program}

\subsubsection*{Project goals and objectives.} 

Our core project team combines two experts in R programming
(Anderson, Lyons) with three biomedical researchers (Gonzalez-Juarrero,
Henao-Tamayo, and Robertson) who have, collectively, spent decades in
laboratory-based research to improve understanding of tuberculosis and other
diseases. We met as fellow faculty members of the College of Veterinary Medicine \& Biomedical Sciences at Colorado State
University, and since have discovered that many of the tools that Drs. Anderson
and Lyons teach and use to improve the reproducibility of \textit{data analysis}
for biomedical research can substantially improve reproducibility and
transparency in the laboratory-based biomedical research projects of Drs.
Gonzalez-Juarrero, Henao-Tamayo, and Robertson at the stages of \textit{data
recording} and \textit{data pre-processing}. Improving the computational 
reproducibility of research at these stages is critical, as these steps form the foundation, and 
provide input, for the later stages of data analysis, visualization and 
interpretation. If data recording and pre-processing are not computationally reproducible, there 
is no chance to make the full research project reproducible.
Further, improving the computational reproducibility of the steps of data recording and pre-processing has other key advantages for laboratory-based researchers, including making collaborations with
statisticians 
and data analysts more efficient and less prone to errors \cite{ellis2018share}, 
and so encouraging productive and high-quality ``Team Science" to tackle large biomedical research projects \cite{munafo2017manifesto}.

Over the past year, our team of co-investigators has begun
to work together to improve the computational reproducibility of experimental data recording and pre-processing within our own research projects. For example, in
Fall 2017 Dr. Gonzalez-Juarrero attended Dr. Anderson's (PI) course in \textit{R
Programming for Research} and has brought the ideas and techniques back to her
research laboratory, and in Spring 2018 Dr. Henao-Tamayo and Dr.
Anderson began co-advising a graduate student to implement
open-source tools for pre-processing flow cytometry in Dr. Henao-Tamayo's
laboratory. Collectively, we are passionate about the idea that
\textbf{open-source tools can be used to substantially improve the
reproducibility of data recording and pre-processing in laboratory-based
biomedical research}, and yet we are also able to recognize that \textbf{there are key barriers in
implementing these tools in this setting, as well as in training
laboratory-based researchers how to use these tools}. 

Through this project, we aim to create training modules that will teach laboratory-based biomedical
researchers how simple computational reproducibility principles can improve
reproducibility at the stages of data recording and
pre-processing. The importance of \textit{computational reproducibility}---in which all
data and code for a research project is openly available and can be used to regenerate study findings either by the original researcher or by
other researchers---is increasingly recognized by scientists, journals, and funding
agencies \cite{ellis2018share, ram2013git}. The reproducibility of the steps of data recording and pre-processing is typically 
in the hands of laboratory-based, rather than computationally-based, researchers.
While many excellent free training resources exist to improve the computational
reproducibility of biomedical research, most of these
materials---including some developed by Dr. Anderson for her online and
CSU-based courses in R programming \cite{andersoncoursebook, andersonmastering}---target researchers at the stage of
\textit{data analysis} for the audience of \textit{computationally-based researchers}, and provide much less guidance on the principles and
techniques to improve reproducibility of the earlier steps of
\textbf{experimental data recording} and \textbf{experimental data
pre-processing} for \textbf{laboratory-based researchers}. 

Among our team, we have
found that there are many common existing practices---including use of
spreadsheets with embedded formulas that concurrently record and analyze
experimental data, problematic management of project files,
and reliance on proprietary, vendor-supplied point-and-click software for data
pre-processing---that can interfere with the transparency, reproducibility, and
efficiency of laboratory-based biomedical research projects. These problems have also been 
identified by others as key barriers to research reproducibility 
\cite{broman2018data, bryan2018excuse, ellis2018share, marwick2018packaging}.
Our team has worked together to craft a list of
specific topics (Tables \ref{tab:content_one} and \ref{tab:content_two}) we will address in these training modules, choosing topics that tackle barriers to reproducibility that have
straightforward, easy-to-teach solutions, but which we have found are still very common in
biomedical laboratory-based research programs, including those here at Colorado
State University. Training materials that are short, 
modular, and accessible can help fill a critical need in providing laboratory-based biomedical researchers this needed
training \cite{munafo2017manifesto} and have proven very popular in providing 
similar training to the audience of data scientists and statisticians \cite{leek2015opinion}. Our project's \textbf{primary goal} is to develop
training modules that address the needs of laboratory-based biomedical
researchers seeking to improve reproducibility, especially of experimental data
recording and pre-processing, in their research projects. The \textbf{expected result} of
this project is an online book that contains twenty short training modules as separate
chapters, with video lectures, written text, and additional educational
materials collected within each module's chapter. We consider it critical that
these training materials be clear, relevant, and useful to a key audience of
biomedical scientists whose primary research activities focus on laboratory
research, rather than data analysis or statistics. 

\subsubsection*{Proposed training modules}

We propose to develop two sequences of modules, \textbf{Improving the
Reproducibility of Experimental Data Recording} and \textbf{Improving the
Reproducibility of Experimental Data Pre-Processing}. Our team has worked
together to create a curriculum of training modules that we believe will help
fill an important training gap for laboratory-based biomedical researchers
(Tables \ref{tab:content_one} and \ref{tab:content_two}). The first sequence,
\textbf{``Improving the Reproducibility of Experimental Data Recording"} (Table
\ref{tab:content_one}), will explore the pitfalls of combining experimental data
recording and analysis within formula-enabled spreadsheets, explain the power of
structured data formats for recording data, describe how reproducibility can be
improved by using a single structured directory to store all research project
files, and demonstrate the use of version control to maintain single, current
versions of all files while saving a history of all file changes. The second
sequence, \textbf{``Improving the Reproducibility of Experimental Data
Pre-Processing"} (Table \ref{tab:content_two}), will focus on improving the
reproducibility of experimental data pre-processing steps, like gating for flow
cytometry data and feature extraction / quantification for mass spectrometry data.
Training materials will explain how the use of code scripts for these pre-processing steps
dramatically improves reproducibility compared to using vendor-supplied
point-and-click software and will introduce trainees to popular R software for
this pre-processing. This sequence will also include advice on the use of reproducible data
pre-processing protocols and how to create these protocols using literate programming tools (\textit{Rmarkdown}).

Each module will fall into one of three categories for teaching reproducibility:
(1) \textit{Principals}; (2) \textit{Implementation}; and (3) \textit{Examples}. \textit{Principals}
modules will be programming-language agnostic, while \textit{Implementation} modules
will focus on tools available through the popular open source R software and its
\textit{RStudio} interface. \textit{Examples} modules will provide materials that can be used as a template for implementing R-based tools, but can also provide a top-level overview for non-programmers of how these tools can improve real biomedical research projects. By co-authoring the modules with the biomedical laboratory-based co-investigators
on our team, we will ensure that these modules and the examples used in them are
approachable and useful to researchers with limited computational training. We
have divided the content into modules in a way that will allow \textbf{trainees
and investigators at any level} to create their own ``tracks" by selecting
relevant subsets of the modules to complete, potentially combining this
content with other training modules available through the National Institute of General Medical Science's \textit{Clearinghouse for Training Modules to Enhance Data Reproducibility}
\cite{clearinghouse} to create a training experience aligned with their individual training needs. Table \ref{tab:tracks} gives a few examples of how different trainees
could create and follow their own ``track" through the training materials we propose to develop.

\underline{\textbf{Sequence 1: Improving the Reproducibility of Experimental Data
Recording}} 

The first sequence will provide principles and tools for improving
computational reproducibility at the stage of experimental data recording. This sequence will include eleven modules covering four main topics: 

\textbf{1. Separating data recording and analysis.} Many biomedical laboratories currently use spreadsheets---with formulas creating underlying connections between spreadsheet cells---to jointly record, visualize, and analyze experimental data \cite{broman2018data}. This practice impedes the transparency and reproducibility of both data recording and data analysis. When a research group develops and uses an evolving spreadsheet template with embedded formulas, it leads to a data recording / analysis process that can become extraordinarily opaque and complex (Figure \ref{fig:spreadsheet}). To improve the computational reproducibility of a research project, it is critical for biomedical researchers to learn the importance of maintaining recorded experimental data as ``read-only" files, separating data recording from any data pre-processing or data analysis steps \cite{broman2018data, marwick2018packaging}. Statisticians have outlined specific methods that a laboratory-based scientist can take to ensure that data shared in an Excel spreadsheet are shared in a reliable and reproducible way, including avoiding macros or embedded formulas, using a separate Excel file for each dataset, recording descriptions of variables in a separate code book rather than in the Excel file, avoiding the use of color of the cells to encode information, using ``NA" to code missing values, avoiding spaces in column headers, and avoiding splitting or merging cells \cite{ellis2018share, broman2018data}. These topics will covered in a \textit{Principles} module on ``Separating data
recording and analysis". 

\begin{figure}[t] \centering \includegraphics[width =
0.8\textwidth]{figures/algorithms.png} \caption{An \textit{xkcd} cartoon
captures the ballooning complexity and lack of transparency that can result from
a group using an evolving spreadsheet with formulas connecting cells. This practice can be a
critical barrier to reproducibility and transparency in biomedical research, yet
is still a common practice in many biomedical laboratories \cite{broman2018data, marwick2018packaging}. \textit{Source: xkcd
by Randall Munroe}} \label{fig:spreadsheet} \end{figure}

\textbf{2. Using a structured data format to record data.} Every extra step of data
cleaning is another chance to introduce errors in experimental biomedical data, and yet laboratory-based researchers often share experimental data with collaborators in a format that requires extensive additional cleaning before it can be input into data analysis \cite{broman2018data}. Recording data in a ``structured" format brings many benefits for later stages of the research process, especially in terms of improving reproducibility and reducing the probability of errors in analysis \cite{ellis2018share}. Data that is in a structured, tabular, two-dimensional format is substantially easier for collaborators to understand and work with, without additional data formatting \cite{broman2018data}. Further, by using a consistent structured format across many or all data in a research project, it becomes much easier to create solid, well-tested code scripts for data pre-processing and analysis and to apply those scripts consistently and reproducibly across datasets from multiple experiments \cite{broman2018data}. However, many biomedical researchers are unaware of this simple yet powerful strategy in data recording and how it can improve the efficiency and effectiveness of collaborations \cite{ellis2018share}. 

The ``tidy" data format is one implementation of a tabular, two-dimensional structured data format that has quickly gained popularity among statisticians and data scientists since it was defined in a 2014 paper \cite{wickham2014tidy}. The ``tidy" data
format plugs into R's \textit{tidyverse} framework, which enables powerful and
user-friendly data management, processing, and analysis by combining simple
tools to solve complex, multi-step problems
\cite{ross2017declutter, silge2016tidytext, wickham2016ggplot2, wickham2016r}. Since the \textit{tidyverse} tools are simple and share a
common interface, they are easier to learn, use, and combine than tools created
in the traditional base R framework \cite{ross2017declutter, lowndes2017our,
reviewer2017review, mcnamara2016state}. This \textit{tidyverse} framework is
quickly becoming the standard taught in introductory R courses and books
\cite{hicks2017guide, baumer2015data, kaplan2018teaching, stander2017enthusing,
reviewer2017review, mcnamara2016state}, ensuring ample training resources for
researchers new to programming, including books (e.g., \cite{baumer2017modern,
lifesciencesR, wickham2016r}),
massive open online courses (MOOCs), on-site university courses
\cite{baumer2015data, kaplan2018teaching, stander2017enthusing}, and Software
Carpentry workshops \cite{wilson2014software, pawlik2017developing}. Further,
tools that extend the \textit{tidyverse} have been created to enable high-quality data
analysis and visualization in several domains, including text mining
\cite{silge2017text}, microbiome studies \cite{mcmurdie2013phyloseq}, natural
language processing \cite{RJ-2017-035}, network analysis \cite{RJ-2017-023},
ecology \cite{hsieh2016inext}, and genomics \cite{yin2012ggbio}. 

These topic will
be covered in a \textit{Principles} module on ``Principles and power of
structured data formats", two \textit{Implementation} modules on ``The 'tidy'
data format: an implementation of a structured data format" and ``Designing
templates for tidy data collection", and one \textit{Example} module called
``Example: Creating a template for 'tidy' data collection". 

\textbf{3. Managing all research project files in a single, structured directory.}
Reproducibility can also be improved, starting at the data recording stage or
earlier, by using a single, structured directory to store all files related to the
project. This ``project" framework of structured and thoughtful file management has recently been encouraged by a number of
researchers as a way to enable computationally reproducible research, especially
for research conducted by teams \cite{marwick2018packaging,
parker2017opinionated, lowndes2017our}. If a consistent structure is used for these directories across different research projects, it can substantially increase the efficiency of, and reduce errors in, data pre-processing and analysis, as code scripts can be created that can be re-used across different project directories with few required changes \cite{marwick2018packaging}. This practice also improves the efficiency and effectiveness of collaborations with statisticians, as it allows the researchers to share critical research project files---raw data, processed data, and code scripts for extracting the processed data from the raw data \cite{ellis2018share, shade2015computing}---in a single, zipped file. Further, some have suggested that if researchers learn better practices for cleanly and consistently managing project files, it will help increase they willingness to share those files and so meet standards of reproducibility \cite{marwick2018packaging}. 

One implementation of this practice is as an \textit{RStudio} ``Project". In \textit{RStudio}, a researcher can collect all project files in a single, structured directory and save this directory as a ``Project" \cite{rstudiousingprojects}. \textit{RStudio} ``Projects" allow easy integration with version control tools (\textit{git}) and online platforms for sharing a directory under version control (\textit{GitHub}, \textit{GitLab}). 
While a ``Project" can have any internal
structure, a common structure can be enforced across multiple research projects
through the creation of a new ``Project" template, which defines the required
subdirectories, structure, and file names of common elements for each project's structured directory \cite{rstudioprojecttemplate}. This template, when selected from a menu bar  in \textit{RStudio} by a
future user, will create a new directory with a ``skeleton" structure,
potentially including templated files (e.g., for metadata that a researcher wants to remember to record for each project) \cite{rstudioprojecttemplate}. If there is a standard for organizing files for a researcher's scientific area, this format can be encoded as a reusable template; use of the structure imposed by this template will make it easier for other researchers in the field to easily navigate code and data that is made public in efforts to increase reproducibility \cite{marwick2018packaging}. 

These topics will be
covered in a \textit{Principles} module on the ``Power of using a single
structured 'Project' directory for storing and tracking research project files",
an \textit{Implementation} module on ``Creating 'Project' templates", and an
\textit{Example} module called ``Example: Creating a 'Project' template".

\textbf{4. Implementing version control.} As a research project progresses, a typical practice in many laboratory-based research groups is to save new, renamed versions of each file (e.g., ``draft1.doc", ``draft2.doc") \cite{bryan2018excuse}, so that they can revert to earlier versions of a file. However, this practice leads to an explosion of files, and it becomes hard to track which files represent the ``current" state of a project. Version control---which tracks and documents changes to any documents that the user chooses to track in a directory---allows researchers to edit and change research project files more cleanly, keeping a single copy of each file in the directory rather than multiple versions, while maintaining the power to backtrack to previous versions. Further, with version control, ``commit messages" to explain changes, making both the changes and the reasoning behind them transparent. The use of the version control software \textit{Git} has been encouraged as a tool to enable reproducible research \cite{piccolo2016tools, ram2013git, bryan2018excuse, lowndes2017our, cetinkaya2017infrastructure}. Once a researcher has learned to use \textit{git} on their own computer for local version control, they can begin using version control 
platforms (e.g., \textit{GitLab}, \textit{GitHub}) to collaborate with others in their research
group while keeping the project under version control \cite{bryan2018excuse, shade2015computing}. Platforms like \textit{GitHub} and \textit{GitLab} allow
the all collaborators to share a current version of a project directory 
(similar to Dropbox), but in a way that allows easy use of version control 
and that is more efficient for exploring (and, when necessary, undoing) the changes 
each team member has made to project files \cite{bryan2018excuse}. For many years, using \textit{Git} version control required use of the command line,
limiting its accessibility to researchers with limited programming experience.
Graphical interfaces, however, have removed this barrier, and \textit{RStudio} has 
particularly user-friendly tools for implementing version control. At CSU, we have found that \textit{git} and \textit{GitHub} can be taught fairly quickly to researchers in their first programming course, so that they can successfully use \textit{GitHub} to submit class assignments when taught through the \textit{RStudio} / \textit{GitHub} interfaces; others have had similar success at other institution \cite{bryan2018excuse}. These
topics will be covered in two \textit{Principles} modules called ``Harnessing
version control for transparent data recording" and ``Enhance the
reproducibility of collaborative research with version control platforms" as
well as an \textit{Implementation} module on ``Using \textit{git} and \textit{GitLab} to implement
version control". 

\underline{\textbf{Sequence 2: Improving the Reproducibility of Experimental Data
Pre-Processing}}

The second sequence will provide principles and tools for improving
computational reproducibility as
experimental data is pre-processed. By ``pre-processing", we mean the steps 
taken to convert data from the raw data---either collected by hand or output
by laboratory equipment---into a format ready for data analysis. We will focus
particularly on improving reproducibility of pre-processing the complex 
raw data output by laboratory equipment---for example feature identification 
and quantification in mass spectrometry data and gating in flow cytometry data---as well
as general pre-processing steps like normalization and scaling. This sequence will include nine modules covering three main topics: 

\textbf{1. Using code scripts to pre-process experimental data.}The experimental data collected for biomedical research often requires 
pre-processing before it can be analyzed (e.g., gating of flow cytometry data, 
feature identification 
and quantification for mass spectrometry data). While 
proprietary point-and-click software is typically available for this pre-processing,
use of such software can limit the transparency and reproducibility of research and is 
time-consuming when pre-processing tasks are repeated in large research projects. Point-and-click software is used interactively and often does not create a history of steps and choices \cite{pernet2015improving}, at least not in a format that is easy for a statistician to navigate, understand, and check \cite{peng2011reproducible, pernet2015improving}. 
Statisticians have clearly stated that, to ensure research is reproducible and that a collaboration is efficient, they would like to receive raw experimental data (e.g., the direct output from experimental equipment), the processed data (preferably in a 'tidy' format), and an ``explicit and exact recipe" for how the processed data was derived from the raw data \cite{ellis2018share}.
A code script, like an R script, provides this ``explicit and exact recipe". Scripted pre-processing can also help reduce the temptation to manually edit data during pre-processing, including manually changing file formats, which prevents reproducibility and impedes transparency \cite{pernet2015improving}. While many of the pre-processing tasks required for biomedical experimental data are complex (e.g., feature identification and quantification, gating), R has package extensions that can be used for these tasks, many hosted on Bioconductor \cite{huber2015orchestrating}. 
Open-source scriptable
software tools bring other key advantages compared to proprietary software in terms of data
pre-processing, including that open-source choices are transparent and often more robust and easier to extend \cite{cetinkaya2017infrastructure, huber2015orchestrating,
brown2014reproducible, piccolo2016tools, baumer2018lessons}. 
These topics will be covered in one
\textit{Principles} module on ``Principles and benefits of scripted
pre-processing of experimental data" and two \textit{Implementation} modules
called ``Introduction to scripted data pre-processing in R" and ``Simplify
scripted pre-processing through R's \textit{tidyverse} tools".

\textbf{2. Working with complex data types during pre-processing.} Many R functions output data in a format that is ``untidy" \cite{robinson2014broom}, in the sense that it does not comply with the structured ``tidy" format required by R's \textit{tidyverse} tools \cite{wickham2014tidy}. This is particularly true for raw data from many biomedical experiments, especially machine-generated data (e.g., output from a flow cytometer or mass spectrometer). Further, Bioconductor, which hosts many R packages useful for pre-processing and analyzing experimental biomedical data, relies heavily on an object-oriented framework \cite{gentleman2004bioconductor}.  This aids interoperability among Bioconductor packages and helps collect different types of data from an experiment (e.g., expression measurements, phenotypes, and administrative data from an experiment) \cite{gentleman2004bioconductor}, but these data formats are ``untidy", in the sense that they do not follow the format required for \textit{tidyverse} tools \cite{biobroom} While these formats are well-justified within open-source software for pre-processing complex biomedical data, they add a critical barrier for researchers wishing
to implement reproducibility tools \cite{robinson2014broom}. This hurdle can be surmounted by skilled R programmers, but it creates a significant barrier for researchers who are new to scripting tools \cite{robinson2014broom}, and it can reduce transparency of analysis by requiring obscure, lengthy code to extract and tidy data from the complex data object \cite{robinson2014broom}. Very recently, the \textit{broom} and \textit{biobroom} R packages have been developed 
to extract a 'tidy' dataset from many common complex data formats that are output by R functions, including much of the output formats common in pre-processing biomedical experimental data \cite{robinson2014broom, biobroom}.
The \textit{biobroom} package, in particular, can ``tidy" data within many popular Bioconductor data formats, including \textit{ExpressionSet} objects \cite{biobroom}. These topics will be covered in a \textit{Principles} module on ``Complex data types in
experimental data pre-processing", a \textit{Implementation} module on ``Complex
data types in R and Bioconductor", and an \textit{Example} module called
``Example: Converting from complex to 'tidy' data formats".

\textbf{3. Reproducible data pre-processing protocols.} Pre-processing software requires many parameter choices, which can lead to an explosion of possible combinations of ways to pre-process experimental biomedical data \cite{munafo2017manifesto, shade2015computing, pernet2015improving}. To ensure transparent and high-quality biomedical research, it is important to be thoughtful in selecting these parameter values and to keep a detailed record of which parameter values were selected and why. Ideally, a research group should maintain ``protocols" describing this pre-processing that are as detailed and reproducible as their experimental protocols  \cite{gentleman2004bioconductor}. Creating and maintaining such \textit{data pre-processing protocols} helps make it easier and clearer for laboratory-based researchers to share their pre-processing ``recipe" with collaborators and to publish journal articles that meet reproducibility guidelines. It also helps ensure continuity in methods for a research group, ensuring that the same pre-processing is maintained as researchers join and leave the group \cite{shade2015computing}.
Reproducibility tools can be used to create \textit{reproducible data pre-processing protocols}---documents that combine code and text in a ``knitted" document, which can be re-used across experiments and research projects. \textit{RMarkdown} can be used to combine code and text to create these reproducible data pre-processing protocols. These topics will be covered in a \textit{Principles} module called ``Introduction to reproducible data pre-processing protocols", an \textit{Implementation} module on ``RMarkdown
for creating reproducible data pre-processing protocols", and an
\textit{Example} module called ``Example: Creating a reproducible data
pre-processing protocol". 

\underline{\textbf{Choice of tools to include in ``Implementation" modules.}}

To improve reproducibility practices among our target audience of laboratory-based biomedical researchers, it is important
that we provide them with some instruction on how to \textit{implement} the
reproducibility principles presented. For some of these principles, there are
several reasonable and well-developed tools that could be used for
implementations. However, few researchers are interested in learning every tool,
and instead would prefer to learn one set of tools that ``just work", and presenting a single set of tools improves the chance of trainees mastering the tools \cite{brown2018ten}. 

We have therefore chosen for the \textit{Implementation} 
modules to focus on tools from the open-source R programming language ecosystem. R can be
freely, quickly, and easily downloaded and installed to a user's computer,
allowing new users to get started quickly, a critical consideration for usable
scientific software \cite{list2017ten}. R has been maintained for over a decade
by the R Development Core Team and works with all major computing platforms,
ensuring  widespread access, stability, and compatibility, which also helps ensure
ease-of-use \cite{baumer2018lessons, altschul2013anatomy}. R offers a
well-developed environment for creating new tools that extend the core language
\cite{wickham2015r, gentleman2004bioconductor} and includes ample tools for documenting research workflows
\cite{xie2015dynamic, xie2016bookdown}. R's status as a common tool among statisticians and biostatisticians means that its use in early stages of
experimental data recording and pre-processing can help foster closer
collaborations between laboratory-based scientists and statisticians throughout
the research process. \textit{RStudio} is a free, open-source Integrated Development Environment (IDE) for the R programming language. It is actively developed by a team of some of the best R programmers worldwide, including the creators of the \textit{tidyverse} (Hadley Wickham) and \textit{RMarkdown} (Yihui Xie). Some
of the implementation tools---\textit{git} and \textit{GitLab}, for example---are separate from R
but can be mastered much more easily if trainees are taught to use them through
\textit{RStudio}'s user-friendly interfaces rather than using the command line or other
alternative interfaces. 

% We have also selected to focus on this set of tools for
% the \textit{Implementation} modules because two members of our team (Anderson
% and Lyons) use R daily for their own research and so are able to provide much
% better instruction and details on using this set of tools than alternative tools
% for the same tasks. Dr. Anderson also regularly teaches students in her
% department how to use this set of tools through a graduate-level course and has
% developed techniques for helping students new to programming to master R using
% the RStudio interface, including using RStudio's interface to use RMarkdown,
% track a project under git version control, and connect to version control
% platforms to improve collaborative work. 

We appreciate that many laboratory-based biomedical researchers do not know the R language, and
some of them may want to learn more about improving reproducibility without
needing to learn a new programming language. 
Although literacy in programming is increasing in the sciences
\cite{ram2013git}, and many now recommend programming as a critical skill for
all biology Ph.D. students \cite{list2017ten}, expertise
with a scripting language is not universal across biomedical researchers. For this reason, we have
deliberately separated the \textit{Principles} and \textit{Examples} content in our modules
from the \textit{Implementation} modules, so that a researcher can select a track of
our modules that does not require programming knowledge. Further, while all of
the \textit{Implementation} modules are conceptually focused on tools that an R
programmer would use, several of the modules could be appreciated and used to
improve reproducibility without a mastery of R. For example, \textit{RStudio} and its
``Projects" functionality can be used to help manage research project files,
keep them under version control, and interface with \textit{GitLab} without using any R code within the project. Similarly, while
the ``tidy" data format is currently an important implementation common within R
for structuring data, understanding its principles and characteristics does not
require any knowledge of R. In our table of example ``tracks" (Table \ref{tab:tracks}), the track we give for an example Principal Investigator is one example
of a track that requires no prior knowledge of R or other programming
languages.   

\input{tables/module_content_data_recording.tex}

\input{tables/module_content_data_preprocessing.tex}

\input{tables/module_tracks.tex}

\subsubsection*{Format for the training modules}

\textbf{Online book.} We will use an online book to collect all the training
materials we develop in a single online document. Each chapter of the book will contain the
materials for one of the modules listed in Tables \ref{tab:content_one} and
\ref{tab:content_two}, for twenty chapters total. We have created a prototype
(Figure \ref{fig:prototype}) to demonstrate some features of the final book.
Users will be able to quickly navigate through chapters with a navigation bar on
the left of the webpage, with chapter subsection links opening when a chapter is
selected. We will embed a lecture video at the start of the chapter, allowing
a user to watch the video content without leaving the book website. This type of format, 
in which video content is woven together with written text and additional educational materials, has been
praised as an effective format for presenting online training materials \cite{searls2012online}.
The book will
include a link for the trainee to download a copy as a PDF or EPUB file, to use
as a future reference offline if desired. The format also includes buttons that
can be used to share the link to the online book with others through Twitter and
other platforms, as well as a link to the book's \textit{GitHub} repository, to allow
early users of the in-development materials to provide feedback on typos, broken
links, unclear materials, and other issues to iron out as we develop the
materials. 
We will use \textit{GitHub Pages} to
freely post this book online. Dr. Anderson (PI) has previously created two
\textit{bookdown}-based books, \textit{R Programming for Research} \cite{andersoncoursebook} and
\textit{Mastering Software Development in R} \cite{andersonmastering}, and has posted and maintained
\textit{R Programming for Research} online through \textit{GitHub Pages} continuously since Fall 2016, providing evidence of the robustness of this method of dissemination.  

\textbf{Video lectures.} 
Since videos can engage online learners better than some other types of learning materials \cite{searls2012ten}, each chapter will include a video lecture that covers
the module's material, with the approximate length of each lecture listed in
Tables \ref{tab:content_one} and \ref{tab:content_two}. We will record these
video lectures in CSU's Computer Assisted Teaching Support laboratory (see
letter from Dr. Andrew West), which includes equipment and staff for creating
professional-quality video lectures. We will use YouTube to freely host these
videos, which will allow us to embed the video within the text of the module's chapter in the
online book (see Figure \ref{fig:prototype} for an example of how this will look
to trainees).Hosting the video lectures through YouTube will allow
us to take advantage of YouTube's excellent, free, and well-tested platform for
sharing videos, as well as allow us to collect detailed analytics on how often
each video is watched and for how long, to help us assess the use of this
component of the training material. 

\textbf{Additional educational materials.} Each module will contain additional
educational material, to help the trainee absorb the material and assess his or
her mastery of the topics. Depending on the module, this additional content will
either be a quiz, questions for discussion, or an applied exercise (see Tables
\ref{tab:content_one} and \ref{tab:content_two} for the specific material
planned for each module). For many of the \textit{Implementation} modules, these extra educational materials will be applied exercises, since providing tutorials, example code, and example datasets can substantially improve the ability of new users to learn software tools \cite{list2017ten, searls2012ten, via2011ten}. Including quizzes as the additional educational material within some of the modules will help trainees self-evaluate their mastery of the material \cite{searls2012ten, via2011ten}. 

To help engage trainees, we will include audio and
video content walking the trainee through answers and solutions for these
additional materials. While not a substitute for in-person training, these video
and audio discussions helps mimic the detailed
walk-throughs and discussions that we would do after a student attempted these
materials if we were teaching these materials in person. As with the video lectures, we will tape this video
and audio content in CSU's Computer Assisted Teaching Support laboratory. We will host the video content through YouTube and the
audio content through SoundCloud and embed this content in the online book. We will use Google Forms as a free and unlimited way
for us to create the quizzes and embed them in the online book [ref].

\noindent \textbf{Insuring compliance with Rehabilitation Act.} We have plans
for making our proposed training module compliant with the
Rehabilitation Act, as amended by the Workforce Investment
Act of 1998. Much of the online content will be text based. For figures and
other images in the book, we will use \textit{alt} and \textit{longdesc} attributes
within the image tag to provide a text alternative. Using YouTube to host the
lecture videos will allow us to draw on that platform's functionality for accessibility,
including ``enough time" functionality, in terms of being able to pause and turn
off the content. YouTube allows users to add and edit closed caption content on
their videos, which we will use to add optional closed captions to this
content---in addition to improving accessibility of the content, it may also
help trainees for whom English is a second language to follow the video lectures. In
the first two years of the grant, our team will include a student hourly who will assist
Dr. Anderson in the technical implementation of the online book, and helping to
ensure the content is compliant with the Rehabilitation Act will be one of his or her
key tasks. If this task requires the use of interesting techniques or
technologies, Dr. Anderson and the student may prepare a journal article
describing these techniques and submit it to \textit{The R Journal} during the
project period. The R community is very open to and interested in improving
accessibility, as evidenced by previous publications, presentations, and
software on these topics (e.g., \cite{uswebr, godfrey2013statistical}).

\subsection{Team}

\input{tables/team_description.tex}

Our core team (Table \ref{tab:team_description}) combines experts in R programming (Anderson, Lyons) with
laboratory-based biomedical researchers in microbiology and immunology
(Henao-Tamayo, Gonzalez-Juarrero, Robertson) who are \textbf{attuned to the
needs of and barriers to improving the reproducibility of experimental data
collection and pre-processing among laboratory-based biomedical researchers}.
Our team will allow us to develop training modules that present state-of-the-art
approaches and tools for reproducibility, but do so in a way that is prioritized
to be most useful and accessible to biomedical researchers whose training has
focused on laboratory-related, rather than computational, research. 

\noindent Our team will also include a to-be-named undergraduate student hourly and Dr. Julie Maertens (Research Associate), a senior evaluator
at the Colorado State University STEM Center. The student hourly will assist Dr. Anderson
in the technical work of publishing the content our team develops in an online book. 
Dr. Maertens will assist in the design and
implementation of project evaluation throughout this project. Dr. Maertens will
only be involved in the project to assist in planning and implementing
evaluation, and her percent effort is capped at 0.85\% to reflect the RFA's
budget restriction of \$3,000 on program evaluation, including salary
support.

\subsubsection*{Coordination and management of the team}

\input{tables/team_roles.tex}

The Principal Investigator and all four Co-Investigators will collaborate to 
develop the materials in the training modules. We have designed a plan (Table \ref{tab:roles}) in which, for each module, Dr. Anderson and one of the Co-Investigators will collaborate as the \textbf{primary authors} of the written text, lecture slides, and additional education materials (quiz, discussion questions, or applied exercise). A second co-investigator will serve as the \textbf{first tester} of the module and will evaluate and test all module material, providing detailed feedback to the two authors of the module to allow them to refine the material. The training materials for the module will then be tested in an in-person CSU pilot testing session (sessions will occur twice per year over the project period, with each session testing the content for approximately five modules), and further refined based on that feedback, as well as on feedback from the two Co-Investigators who did not have roles of author or first tester for that module, and any feedback from early online users. After this refinement based on early feedback, Dr. Anderson will film the video lecture for the module.  
Throughout the module development period (first two years of the project), Dr. Anderson and the undergraduate student will transfer the developed training content into the online book format and publish it online, and Dr. Anderson will be in charge of maintaining and updating the online material during the third project year. Dr. Anderson will lead the planning and implementation of the CSU pilot testing sessions and other activities related to pilot testing and refinement of the training modules. Dr. Maertens will assist Dr. Anderson at points throughout the project period to develop materials for evaluation, including feedback surveys to use with CSU pilot testers, survey questions to include in the online book for evaluation purposes, and brief training on how to best elicit qualitative feedback from pilot testers during the biannual CSU pilot testing sessions. The four co-investigators will play key roles in disseminating the training materials to our key audience, as they are all well-connected withing the microbiology and immunology research communities. Throughout the project period, Dr. Anderson, the four co-investigators, Dr. Maertens, and the student hourly will meet as a group at least four times per project year to check in on progress on the project. 

Our plan of content development and publishing is ambitious, but we are
confident we can meet it. Dr. Anderson previously developed the online content,
in collaboration with a co-instructor, for a five-course specialization (\textit{Mastering Software Development with R}, see letter from Dr. Roger Peng) with
approximately twice as much content in under nine months. She has experience
developing and publishing online training materials for learning R-based tools,
including through the \textit{bookdown} online book framework we plan to use
here. In this previous development of online training materials, Dr. Anderson
learned to collaborate closely with co-authors in developing and refining online educational
content and in developing quizzes and applied exercises to allow trainees to
test their understanding of that content. She will bring that experience in the
proposed project, to help organize and integrate the contributions of our team
of co-investigators. For the technical development of the book, she will be
assisted by and supervise an undergraduate hourly during the first two years of
the project, to help in turning the intellectual content that she and the
co-investigators develop into the formatted online book. 

\subsection{Institutional Environment and Commitment}

Colorado State University is a Research I institution, with vibrant research programs in a variety of scientific, engineering, and health-related fields. As Colorado's land-grant university, CSU has a 100-year-old extension program to help researchers disseminate their research results to members of the wider community and strongly values its history and continuing commitment to sharing cutting-edge scientific knowledge through outreach education activities. Colorado State University is very supportive of improving the reproducibility of
research, and it offers ample resources that will help us ensure the success of
the proposed project. \textbf{Our institution has clearly expressed its support
for our proposed effort to create, refine, evaluate, and disseminate these
training materials} in institutional letters of support from Dr. Jac Nickoloff
(Chair of the Department of Environmental \& Radiological Health Sciences, CSU),
Dr. Dean Gregg (Chair of the Department of Microbiology, Immunology, \&
Pathology, CSU), and Dr. Alan Rudolph (Vice President for Research, CSU). As
expressed in the letter of support from Dr. Nickoloff, Dr. Anderson's teaching
expectations during the project period are capped at three courses every two
years, allowing adequate time for her to complete the tasks required by this
proposal. As also expressed in that letter, Dr. Anderson's department supports
that the training materials developed under this grant will be made freely
available through online publication under a Creative Commons license. Dr.
Anderson's department has supported her previous development and publication of
similarly free and open training materials following a similar format \cite{andersoncoursebook, andersonmastering}.

Colorado State University is host to a large number of laboratory-based
biomedical researchers, especially in fields related to drug and vaccine
development for infectious diseases. We will \textbf{take advantage of this
environment} to help us pilot test and refine the training materials, to ensure
they are clear, relevant, and useful to our target population of
laboratory-based biomedical researchers. We have received statements of support
from relevant programs---including the director of the CSU Interdisciplinary
Graduate Program in Cell \& Molecular Biology and the Associate Director of the
Interdisciplinary NSF-NRT GAUSSI training program in Computational Biology---to
help disseminate our materials to pilot testers and early users of our training
materials on-campus at CSU (see letters from Drs. Dean Gregg, Carol Wilusz, and Jeff
Wilusz). 

CSU provides meeting rooms
that we can reserve free-of-charge to use for the CSU-based user testings. The
Computer Assisted Teaching Support (CATS) laboratory at CSU's Academy for
Teaching and Learning has professional-grade recording equipment that we will
use to record the video lectures within each module (see letter from Dr. Andrew
West), and CSU's STEM Center will provide help in evaluating the training modules,
including through the budgeted involvement of Dr. Julie Maertens, a senior
evaluator at the center. 

\subsection{Piloting and evaluating the effectiveness of the training modules}

\begin{quotation} ``Applications must include a plan for evaluating the
activities supported by the award in terms of their \textbf{frequency of use}
and their \textbf{usefulness}. The use of \textbf{multiple evaluation
approaches} is highly encouraged as is \textbf{testing several groups with
different characteristics}. The application must specify \textbf{baseline
metrics (e.g., numbers, educational levels, and demographic characteristics of
test group)} in a structured format, as well as \textbf{measures to gauge the
short and long-term success of the research education award in achieving its
objectives}. Applicants are expected to \textbf{obtain feedback from test group}
to help identify weaknesses and to provide suggestions for improvements, and
\textbf{make the evaluation and feedback data} available to NIGMS staff."
\end{quotation}

\textbf{Pilot testing}

\textbf{We will pilot test the training materials using three methods: (1) biannual on-campus  day-long pilot testing at Colorado State University (two sessions per project year, six total over the project); (2) a workshop at the [AAM] in year 2 of the project; and (3) early online users of the training materials.} We expect that these different methods will allow us to collect different sets of 
feedback on the frequency of use and usefulness of the training materials (Table \ref{tab:evaluation}), providing a rich collection of ideas for us to use in refining the materials. Examples of what we hope to learn from each group in pilot testing and evaluation (Tables \ref{tab:evaluation}). For each of the modules, we have outlined learning objectives will help us evaluate if the training modules are useful in achieving their educational goals (Tables \ref{tab:content_one} and \ref{tab:content_two}).

\textbf{Biannual Colorado State University pilot testing sessions.}
We will conduct two, day-long pilot testing sessions at CSU in each year of the
project. The CSU pilot testing participants will include current and future
laboratory-based biomedical researchers. We will recruit trainees with a variety
of research roles, including undergraduate students, graduate students,
postdoctoral fellows, research associates, and principal investigators. We have
informed several CSU biomedical researchers about these proposed testing
sessions and received their support in encouraging CSU researchers within their
groups and departments to participate (see letters from Drs. Gregg Dean, Carol Wilusz, and Jeff Wilusz). 

In the first two project years, each session will test the set of modules
developed since the last user testing (approximately five modules will be tested
each of these session). The sessions will begin with our team giving live
lectures of the same content we plan to film for the video lectures included in
the online book. This will allow us to improve and refine this content, based on
detailed feedback from testers representative of our target audience, before
filming the final video lectures. During the rest of the session, we will divide
the trainees into small teams to work through the additional educational
materials (applied exercises, quiz questions, and discussion questions) to iron
out problems with the clarity or implementation of these materials. The trainees
will have access to the in-development online book as they work through these
materials. In the last year of the project, these sessions will revisit the material
in modules that proved problematic in their first round of pilot testing, allowing us
to re-test approximately ten of the modules (five tested per session in project year 3).
To solicit specific feedback from these sessions, we will survey the participants during the sessions (for examples of the types of feedback we will collect through these surveys, see Table \ref{tab:evaluation}). Six months after each pilot testing session, we will send participants a follow-up survey, to help evaluate longer-term success of the training in improving the reproducibility of data recording and pre-processing. Dr. Anderson (PI) has experience in productively conducting these kinds of user
testing sessions at CSU. She has run several two-hour user testing sessions with
students from various departments of Colorado State University prior to
releasing R software packages \cite{futureheatwaves, countyweather}. Further, in
April 2016, she led a longer, two-day user testing session through a Weather
Data Hackathon at Colorado State University (Figure \ref{csu-r-hackathon}).
Some of the ideas and code developed during this Hackathon have
since led to development and publication of open source software
\cite{countyfloods, noaastormevents}.

\begin{SCfigure} \centering \includegraphics[width =
0.6\textwidth]{figures/csu_hackathon.png} \caption{Some of the approximately 15
undergraduate students, graduate students, postdoctoral fellows, and professors
who participated in a two-day Weather Data Hackathon at Colorado State
University in April 2016 led by Dr. Anderson. Around 15 people participated, including from CSU's Departments of
Atmospheric Sciences, Civil \& Environmental Engineering, Microbiology, and
Statistics. } \label{csu-r-hackathon}
\end{SCfigure}

\textbf{American Society for Microbiology pre-conference workshop.}
The American Society for Microbiology presents pre-conference workshops at its annual 
conference, for which scientists can submit proposals. We will submit a proposal 
to lead a day-long workshop at the ASM conference in year 2 of the project. This 
workshop will cover the content of most of the training modules listed in Tables
\ref{tab:content_one} and \ref{tab:content_two}. It will include live lectures of the 
materials from the online video lectures, as well as directed work through the 
additional educational materials for each module. As with the CSU pilot testing sessions, we will use surveys to get immediate and follow-up (six months after, to evaluate longer-term outcomes) feedback from 
the participants of this workshop.

\textbf{Early online users.}  We will develop the book openly online from the start of 
the project, including posting all underlying code online at \textit{GitHub} and 
posting the current version of the online book through \textit{GitHub Pages}, using 
\textit{Travis Continuous Integration} to rebuild the book each time we commit 
changes to its underlying code. Dr. Anderson has used a similar development process
with an online coursebook \textit{andersoncoursebook}; this open development process
helps attract early users and also provides book users with a real-life view of how 
version control tools and platforms can enable ``live" development of a project. We will 
have a first version of the written text for the online book for at least five of the 
modules ready by the first CSU pilot testing session (approximately six months into year 1 of the project); at this point, we will actively recruit early online users through
social media and through our networks R users (Anderson and Lyons) and biomedical researchers (Gonzalez-Juarrero, Henao-Tamayo, and Robertson). We will enable Google Analytics on the online book's webpage, which will allow us to track how many people 
access the online book, how often they stay on the book's page, and the distribution of these early users across the United States and the world. 
Similarly, analytics from the platforms we use to host embedded material (YouTube,
SoundCloud, and Google Forms) will allow us to track the use of those materials.
We will also use Google Forms to create voluntary surveys within the online book, to generate additional feedback from these early users in terms of their characteristics and on the usefulness of the modules.  While this voluntary survey will not provide data on \textit{all} early online users, it will help characterize a collection of the users, and we selected to make the survey voluntary (rather than required to access the book) in hopes of making the book as accessible as possible, and to avoid discouraging users who might be drawn in by browsing the materials before committing to provide their information or feedback.

\textbf{External program evaluation}

An external evaluation of the proposed training modules program will be conducted by Julie Maertens in the Colorado State University STEM Center, which facilitates collaborations among STEM-related education and outreach projects within and outside CSU. Dr. Maertens has conducted several large-scale, multi-site youth program evaluations in conjunction with the State of Colorado, and also regularly works with researchers in- and outside of Colorado to implement STEM education and outreach evaluations. She currently leads the evaluation of three federally funded projects designed to: (1) Create a pre-service secondary teacher program that integrates the requirements for traditional engineering undergraduate degree programs; (2) Improve recruitment and persistence of women in the geosciences using a deliberate mentorship approach, and (3) Improve recruitment and retention of underrepresented minorities in computational biology and genomics by creating and conducting week-long workshops in Todos Santos, Mexico.

The conceptual framework for the evaluation will be organized using the CIPP model, which is designed to guide project decision-making based on assessment of a program’s context, input, process and product \cite{stufflebeam2004cipp}. The operational framework will use observable data to conduct both formative [F] and summative [S] evaluation of the program, and will focus on 2 main areas of the conceptual evaluation model to determine: 1) How well the program is implemented (\textit{process}), and 2) How well the proposed modules and training activities meet the program objectives (\textit{product}).

Evaluation data will include baseline program metrics as well as measures to gauge the short- and long-term success of the proposed training modules in achieving program objectives. Examples of data to be collected include:

\begin{itemize}
\item Number, educational level, and demographics of online module users (where available; survey participation is optional)
\item Brief post-course evaluation of module usefulness (e.g., accessibility, content, goals, structure, overall experience) among online module users (where available; survey participation is optional)
\item Number, educational level, and demographics of in-person test users
\item In depth, 15-point post-course evaluation of module usefulness among in-person test users
\item Follow-up surveys among in-person test users to determine future usefulness of the modules (e.g., how and whether module content is applied to future research activities)
\item Project team implementation surveys
\end{itemize}

In addition to the proposed data collection, Dr. Maertens will train the project team to collect qualitative data among test users during the day-long user testing sessions (on-campus at CSU and at the ASM workshop), and how to use a qualitative content analysis process to extract ‘themes’ related to feedback (e.g., strengths, weaknesses) about the modules. These themes may be used, along with the evaluation survey data, to make iterative improvements to the modules each year.

Survey results will be presented annually via written report, and will summarize all findings and iterative program changes and provide recommendations for future programming. See Table \ref{tab:external_evaluation} for evaluation questions and methods.

\input{tables/external_evaluation.tex}

\subsection{Dissemination Plan}

Using \textit{GitHub Pages}, we will publish the book freely online, with all materials published under the Creative Commons Attribution-ShareAlike 4.0 International License, \textbf{making all materials freely accessible, both nationally and internationally}. From the beginning of the project, we will publish the book online as it develops, and we will promote this material through social media (e.g., Twitter) and through our network of colleagues in biomedical research and the R programming community (for example, see letter of support from Dr. Peng). Since this book will be hosted online, it will be easy to link to from the National Institute of General Medical Sciences \textit{Clearinghouse for Training Modules to Enhance Data Reproducibility} \cite{clearinghouse}. There will be no paywall or other restriction on accessing any of the training materials, and source code for the book and exercises will be published on \textit{GitHub}. All video and audio content will be published online in free formats through YouTube and SoundCloud, with the content embedded in the online book (see Figure \ref{fig:prototype}. At the end of project years 2 and 3, we will also post a static version of the book to the website \textit{bookdown.org}, where people can go to find free online books published using the \textit{bookdown} format and which invites direct submissions from authors that have used these framework. 

In addition to these methods of disseminating the training materials to a general audience, \textbf{we will also take specific steps to make sure that our target audience---laboratory-based biomedical scientists---are aware of these training materials.} We will apply to present posters or oral presentations in years 2 and 3 of the project at three national and international conferences (American Society for Microbiology Conference, American Association of Immunologists Meeting, and International Society for the Advancement of Cytometry) to pilot the training materials and help get out the news among our target audience that these materials are freely available. We will also apply to present a workshop in year 2 of the project at the American Society for Microbiology Conference to pilot the training materials and help get out the news among our target audience that these materials are freely available. We will pilot our training materials among CSU researchers in our target audience through biannual, day-long user testing; in addition to providing us with feedback to help refine our materials, this will help us let members of our target audience know that these training materials are freely available and how to find them. We will also invite colleagues (and their research group members) at and outside of CSU to serve as early online users of the our materials. In addition to providing us with feedback to help refine our materials, this will help us disseminate the materials. Finally, we will write and submit a paper describing these training materials and highlighting their content in a biomedical journal relevant to our target audience.

The PI has previously had substantial success in disseminating online training materials. She is the co-instructor of a five-course specialization on \textit{Mastering Software Development in R} through the Massive Open Online Course platform Coursera. This series has had over 50,000 participants since it was opened in Fall 2016, and an accompanying online book on the LeanPub platform has been downloaded by over 14,000 people.

\subsection{Potential Pitfalls and Alternative Plans}

We have high confidence that we will be able to successfully develop, test, refine, and disseminate the training materials as outlined in this proposal, based on our previous success with similar project \cite{andersonmastering, andersoncoursebook}. However, we have considered alternative plans in case there are complications in the project. If there are any problems in disseminating the full collection of training materials using the \textit{bookdown} format and with free web hosting through \textit{Git Pages}, we will explore using the \textit{DataCamp} platform \cite{datacamp} to host the training materials. This is a well-developed online learning platform, and it allows academics to develop and post their own training materials through ``Course Editor". Content that is created and published through the ``Community" section of DataCamp are freely accessible to anyone \cite{authoringdatacamp}.  

\clearpage

\subsection{Timeline}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/timeline.pdf}
    \caption{Timeline for proposed activities for this project.}
    \label{fig:timeline}
\end{figure}

\clearpage

\bibliographystyle{unsrtnat}
\bibliography{rep_modules}

\end{document}
